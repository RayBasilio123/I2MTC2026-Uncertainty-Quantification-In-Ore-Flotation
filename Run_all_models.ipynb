{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_GArG996vjS",
        "outputId": "b85bac26-15c4-48c2-efa1-54f563f85746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ngboost\n",
            "  Downloading ngboost-0.5.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting lifelines>=0.25 (from ngboost)\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from ngboost) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.6 in /usr/local/lib/python3.12/dist-packages (from ngboost) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.7.2 in /usr/local/lib/python3.12/dist-packages (from ngboost) (1.16.1)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.12/dist-packages (from ngboost) (4.67.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.12/dist-packages (from lifelines>=0.25->ngboost) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.12/dist-packages (from lifelines>=0.25->ngboost) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.12/dist-packages (from lifelines>=0.25->ngboost) (1.8.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines>=0.25->ngboost)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines>=0.25->ngboost)\n",
            "  Downloading formulaic-1.2.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0,>=1.6->ngboost) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0,>=1.6->ngboost) (3.6.0)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines>=0.25->ngboost)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: narwhals>=1.17 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.17.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines>=0.25->ngboost) (1.17.0)\n",
            "Downloading ngboost-0.5.6-py3-none-any.whl (35 kB)\n",
            "Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.2.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=d8e0bda62fa9ea14a150f0b565b06e83a6deca33f840f46ea81beb0f54d0b6d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/37/21/0a719b9d89c635e89ff24bd93b862882ad675279552013b2fb\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines, ngboost\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-1.2.0 interface-meta-1.3.0 lifelines-0.30.0 ngboost-0.5.6\n",
            "Requirement already satisfied: xgboost>=2.0.0 in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost>=2.0.0) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost>=2.0.0) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost>=2.0.0) (1.16.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install ngboost\n",
        "%pip install \"xgboost>=2.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ado9PZjdsb7E"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from ngboost import NGBRegressor\n",
        "    from ngboost.distns import Normal\n",
        "    HAVE_NGBOOST = True\n",
        "except Exception:\n",
        "    HAVE_NGBOOST = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "If_JJ_cSBaa_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxpqTY0X-lQ_"
      },
      "source": [
        "# Seleciona variaveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV_DPVxp-rU3",
        "outputId": "0cb21564-926e-47fc-a1db-8cdc7f96b30d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features candidatas iniciais (sem prefixo 'P'): 42\n",
            "Removidas por |corr| > 0.8: 6\n",
            "Features finais após filtro: 36\n",
            "\n",
            "==== FEATURES FINAIS APÓS O FILTRO DE CORRELAÇÃO ====\n",
            "Total: 36\n",
            " - TO_AI6401_01\n",
            " - TO_AI6402_01\n",
            " - TO_BO6311_EST1\n",
            " - TO_DI6311_01\n",
            " - TO_FI6311_01\n",
            " - TO_FI8271_01\n",
            " - TO_FY6104_01\n",
            " - TO_LI6401_01\n",
            " - TO_LI6401_02\n",
            " - TO_LI6402_01\n",
            " - TO_LI6411_01\n",
            " - TO_LI6411_02\n",
            " - TO_LI6412_01\n",
            " - TO_LI6412_02\n",
            " - TO_LI6431_01\n",
            " - TO_LI6432_01\n",
            " - TO_MF6401_M1_EST1\n",
            " - TO_MF6402_M1_EST1\n",
            " - TO_MF6411_M1_EST1\n",
            " - TO_MF6412_M1_EST1\n",
            " - TO_MF6421_M1_EST1\n",
            " - TO_PHY4804_02\n",
            " - TO_PHY4814_02\n",
            " - TO_SIMF640101\n",
            " - TO_SIMF640102\n",
            " - TO_SIMF640201\n",
            " - TO_SIMF640202\n",
            " - TO_SIMF641101\n",
            " - TO_SIMF641102\n",
            " - TO_SIMF641201\n",
            " - TO_SIMF641202\n",
            " - TO_SIMF6421\n",
            " - TO_SIMF6422\n",
            " - TO_SIMF6431\n",
            " - TO_SIMF6432\n",
            " - TO_WI4804_01\n",
            "\n",
            "==== TOP-10 POR |CORRELAÇÃO| COM O ALVO ====\n",
            "TO_WI4804_01         0.126832\n",
            "TO_PHY4814_02        0.117796\n",
            "TO_PHY4804_02        0.076092\n",
            "TO_SIMF641201        0.071923\n",
            "TO_LI6412_01         0.060203\n",
            "TO_SIMF640202        0.056755\n",
            "TO_MF6401_M1_EST1    0.050787\n",
            "TO_SIMF6422          0.047890\n",
            "TO_SIMF641102        0.046416\n",
            "TO_FI8271_01         0.046393\n",
            "Name: _y, dtype: float64\n",
            "\n",
            "==== TOP-10 POR IMPORTÂNCIA (XGBoost 'gain') ====\n",
            "             feature       gain\n",
            "0  TO_MF6412_M1_EST1  88.207138\n",
            "1       TO_FI8271_01  48.112823\n",
            "2      TO_PHY4814_02  46.969368\n",
            "3       TO_WI4804_01  46.760201\n",
            "4        TO_SIMF6421  43.839195\n",
            "5       TO_FI6311_01  42.704105\n",
            "6      TO_PHY4804_02  40.105129\n",
            "7        TO_SIMF6431  39.960491\n",
            "8      TO_SIMF640202  39.075539\n",
            "9       TO_LI6411_01  38.721352\n",
            "\n",
            "features1 = ['TO_AI6401_01', 'TO_AI6402_01', 'TO_BO6311_EST1', 'TO_DI6311_01', 'TO_FI6311_01', 'TO_FI8271_01', 'TO_FY6104_01', 'TO_LI6401_01', 'TO_LI6401_02', 'TO_LI6402_01', 'TO_LI6411_01', 'TO_LI6411_02', 'TO_LI6412_01', 'TO_LI6412_02', 'TO_LI6431_01', 'TO_LI6432_01', 'TO_MF6401_M1_EST1', 'TO_MF6402_M1_EST1', 'TO_MF6411_M1_EST1', 'TO_MF6412_M1_EST1', 'TO_MF6421_M1_EST1', 'TO_PHY4804_02', 'TO_PHY4814_02', 'TO_SIMF640101', 'TO_SIMF640102', 'TO_SIMF640201', 'TO_SIMF640202', 'TO_SIMF641101', 'TO_SIMF641102', 'TO_SIMF641201', 'TO_SIMF641202', 'TO_SIMF6421', 'TO_SIMF6422', 'TO_SIMF6431', 'TO_SIMF6432', 'TO_WI4804_01']\n",
            "features2 = ['TO_WI4804_01', 'TO_PHY4814_02', 'TO_PHY4804_02', 'TO_SIMF641201', 'TO_LI6412_01', 'TO_SIMF640202', 'TO_MF6401_M1_EST1', 'TO_SIMF6422', 'TO_SIMF641102', 'TO_FI8271_01']\n",
            "features3 = ['TO_MF6412_M1_EST1', 'TO_FI8271_01', 'TO_PHY4814_02', 'TO_WI4804_01', 'TO_SIMF6421', 'TO_FI6311_01', 'TO_PHY4804_02', 'TO_SIMF6431', 'TO_SIMF640202', 'TO_LI6411_01']\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Config (seus valores)\n",
        "# =========================\n",
        "CSV_PATH    = \"dados_2h_aggregado_final.csv\"   # <-- ajuste o caminho\n",
        "TARGET      = \"P_CONFLTTO_QQ_GLOBAL_SIO2\"\n",
        "TIME_COL    = \"Data\"\n",
        "CORR_THRESH = 0.8\n",
        "TEST_SIZE   = 0.2\n",
        "VAL_SIZE    = 0.2      # fração do treino reservada p/ early stopping\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# =========================\n",
        "# Utils\n",
        "# =========================\n",
        "def read_csv_safely(path):\n",
        "    last_err = None\n",
        "    for enc in (\"utf-8\", \"latin1\", \"cp1252\"):\n",
        "        try:\n",
        "            return pd.read_csv(path, sep=None, engine=\"python\", encoding=enc)\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    raise RuntimeError(f\"Falha ao abrir {path}. Último erro: {last_err}\")\n",
        "\n",
        "def greedy_corr_filter(X_num: pd.DataFrame, thresh: float = 0.8):\n",
        "    \"\"\"\n",
        "    Remove colunas altamente correlacionadas (|corr| > thresh).\n",
        "    Critério: remove a variável com maior média de |corr| com as demais.\n",
        "    \"\"\"\n",
        "    corr = X_num.corr().abs()\n",
        "    ativos = set(corr.columns)\n",
        "    removidos = set()\n",
        "    while True:\n",
        "        cols = sorted(ativos)\n",
        "        if len(cols) <= 1:\n",
        "            break\n",
        "        sub = corr.loc[cols, cols].copy()\n",
        "        np.fill_diagonal(sub.values, 0.0)\n",
        "        max_val = sub.values.max()\n",
        "        if max_val <= thresh:\n",
        "            break\n",
        "        i, j = np.unravel_index(np.argmax(sub.values), sub.shape)\n",
        "        vi, vj = cols[i], cols[j]\n",
        "        to_remove = vi if sub[vi].mean() >= sub[vj].mean() else vj\n",
        "        ativos.remove(to_remove)\n",
        "        removidos.add(to_remove)\n",
        "    return sorted(ativos), sorted(removidos)\n",
        "\n",
        "def fit_xgb_with_es(X_tr, y_tr, X_val, y_val, params=None):\n",
        "    \"\"\"Treina XGBRegressor com early stopping (compatível com diferentes versões).\"\"\"\n",
        "    if params is None:\n",
        "        params = dict(\n",
        "            n_estimators=300,\n",
        "            max_depth=4,\n",
        "            learning_rate=0.06,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=RANDOM_SEED,\n",
        "            n_jobs=-1,\n",
        "            tree_method=\"hist\",\n",
        "        )\n",
        "    model = XGBRegressor(**params)\n",
        "   \n",
        "    try:\n",
        "        model.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=50\n",
        "        )\n",
        "    except TypeError:\n",
        "        try:\n",
        "            from xgboost.callback import EarlyStopping\n",
        "            model.fit(\n",
        "                X_tr, y_tr,\n",
        "                eval_set=[(X_val, y_val)],\n",
        "                verbose=False,\n",
        "                callbacks=[EarlyStopping(rounds=50, save_best=True)]\n",
        "            )\n",
        "        except Exception:\n",
        "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "    return model\n",
        "\n",
        "def rank_features_by_gain(model, feature_names):\n",
        "    \"\"\"\n",
        "    Extrai importância por 'gain'. Se não disponível, cai em feature_importances_.\n",
        "    \"\"\"\n",
        "    booster = model.get_booster()\n",
        "    try:\n",
        "        gain = booster.get_score(importance_type=\"gain\")  # {'f0': gain0, ...}\n",
        "        scores = [gain.get(f\"f{j}\", 0.0) for j in range(len(feature_names))]\n",
        "    except Exception:\n",
        "        scores = list(getattr(model, \"feature_importances_\", np.zeros(len(feature_names))))\n",
        "    df_imp = pd.DataFrame({\"feature\": feature_names, \"gain\": scores})\n",
        "    df_imp = df_imp.sort_values(\"gain\", ascending=False).reset_index(drop=True)\n",
        "    return df_imp\n",
        "\n",
        "# =========================\n",
        "# 1) Ler dados\n",
        "# =========================\n",
        "df = read_csv_safely(CSV_PATH)\n",
        "if TARGET not in df.columns:\n",
        "    raise ValueError(f\"Coluna alvo '{TARGET}' não encontrada no CSV.\")\n",
        "\n",
        "y = pd.to_numeric(df[TARGET], errors=\"coerce\")\n",
        "mask_y = y.notna()\n",
        "df = df.loc[mask_y].reset_index(drop=True)\n",
        "y  = y.loc[mask_y].reset_index(drop=True)\n",
        "\n",
        "# =========================\n",
        "# 2) Seleção inicial de features (exclui prefixo 'P' e não numéricas)\n",
        "# =========================\n",
        "feature_candidates = [c for c in df.columns if not c.startswith(\"P\") and c != TARGET]\n",
        "X = df[feature_candidates].dropna(axis=1, how=\"all\").select_dtypes(include=[np.number])\n",
        "\n",
        "print(f\"Features candidatas iniciais (sem prefixo 'P'): {X.shape[1]}\")\n",
        "\n",
        "# =========================\n",
        "# 3) Remover colinearidade |corr| > CORR_THRESH\n",
        "# =========================\n",
        "kept_cols, removed_cols = greedy_corr_filter(X, CORR_THRESH)\n",
        "X = X[kept_cols].copy()\n",
        "print(f\"Removidas por |corr| > {CORR_THRESH}: {len(removed_cols)}\")\n",
        "print(f\"Features finais após filtro: {X.shape[1]}\")\n",
        "\n",
        "# (opcional) salvar lista completa das features finais (pós-filtro)\n",
        "pd.Series(kept_cols).to_csv(\"final_features_after_corr_filter.txt\",\n",
        "                            index=False, header=False, encoding=\"utf-8\")\n",
        "\n",
        "# =========================\n",
        "# 4) Split temporal (se possível) → depois split do treino p/ validação\n",
        "# =========================\n",
        "time_sorted = False\n",
        "if TIME_COL in df.columns:\n",
        "    order = pd.to_datetime(df[TIME_COL], errors=\"coerce\")\n",
        "    if order.notna().mean() > 0.5:\n",
        "        idx = order.argsort(kind=\"mergesort\")\n",
        "        X = X.iloc[idx].reset_index(drop=True)\n",
        "        y = y.iloc[idx].reset_index(drop=True)\n",
        "        time_sorted = True\n",
        "\n",
        "# Holdout teste\n",
        "if time_sorted:\n",
        "    cut = int((1 - TEST_SIZE) * len(X))\n",
        "    X_train, X_test = X.iloc[:cut], X.iloc[cut:]\n",
        "    y_train, y_test = y.iloc[:cut], y.iloc[cut:]\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED\n",
        "    )\n",
        "\n",
        "# Split treino -> (treino interno + validação) para early stopping\n",
        "if time_sorted:\n",
        "    cut_in = int((1 - VAL_SIZE) * len(X_train))\n",
        "    X_tr_in, X_val_in = X_train.iloc[:cut_in], X_train.iloc[cut_in:]\n",
        "    y_tr_in, y_val_in = y_train.iloc[:cut_in], y_train.iloc[cut_in:]\n",
        "else:\n",
        "    X_tr_in, X_val_in, y_tr_in, y_val_in = train_test_split(\n",
        "        X_train, y_train, test_size=VAL_SIZE, random_state=RANDOM_SEED\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# 5) Importância por 'gain' com TODAS as features do treino interno\n",
        "# =========================\n",
        "imp_rank = SimpleImputer(strategy=\"median\")\n",
        "X_tr_in_imp_full = imp_rank.fit_transform(X_tr_in).astype(np.float32)\n",
        "X_val_in_imp_full = imp_rank.transform(X_val_in).astype(np.float32)\n",
        "\n",
        "base_model = fit_xgb_with_es(X_tr_in_imp_full, y_tr_in.values, X_val_in_imp_full, y_val_in.values)\n",
        "ranking_df = rank_features_by_gain(base_model, X_tr_in.columns.tolist())\n",
        "\n",
        "# =========================\n",
        "# 6) Listas pedidas + impressões/arquivos auxiliares\n",
        "# =========================\n",
        "\n",
        "# 6.1) Lista das features finais após o filtro de correlação\n",
        "features1 = list(kept_cols)\n",
        "print(\"\\n==== FEATURES FINAIS APÓS O FILTRO DE CORRELAÇÃO ====\")\n",
        "print(f\"Total: {len(features1)}\")\n",
        "for f in features1:\n",
        "    print(\" -\", f)\n",
        "\n",
        "# 6.2) Top-N por |correlação| com o alvo (usa X já filtrado e y alinhado)\n",
        "N_TOP = min(10, len(features1))\n",
        "corr_target = pd.concat([X, y.rename(\"_y\")], axis=1).corr()[\"_y\"] \\\n",
        "                 .drop(\"_y\").abs().sort_values(ascending=False)\n",
        "top_corr = corr_target.head(N_TOP)\n",
        "features2 = top_corr.index.tolist()\n",
        "\n",
        "print(f\"\\n==== TOP-{N_TOP} POR |CORRELAÇÃO| COM O ALVO ====\")\n",
        "print(top_corr)\n",
        "\n",
        "# (opcional) salvar correlações\n",
        "top_corr.to_csv(\"top_corr_with_target.csv\", header=[\"abs_pearson\"], encoding=\"utf-8\")\n",
        "\n",
        "# 6.3) Top-N por importância\n",
        "ranking_df.to_csv(\"feature_importance_gain_full.csv\", index=False, encoding=\"utf-8\")\n",
        "top_gain = ranking_df.head(N_TOP).copy()\n",
        "features3 = top_gain[\"feature\"].tolist()\n",
        "\n",
        "print(f\"\\n==== TOP-{N_TOP} POR IMPORTÂNCIA (XGBoost 'gain') ====\")\n",
        "print(top_gain)\n",
        "\n",
        "top_gain.to_csv(\"top_importance_gain.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# 6.4) Visualização final das três listas pedidas\n",
        "print(\"\\nfeatures1 =\", features1)  # finais pós-filtro\n",
        "print(\"features2 =\", features2)    # top-N correlação\n",
        "print(\"features3 =\", features3)    # top-N importância\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqa34NHMm8X_"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#  - MIM (Mutual Information Maximization)\n",
        "#  - Backward Selection (wrapper por validação)\n",
        "#  - GroupFS (seleção por grupos de sensores, forward wrapper)\n",
        "# Compatível com xgboost>=2.1 (usa early_stopping_rounds no __init__)\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# =========================\n",
        "# Config (ajuste conforme precisar)\n",
        "# =========================\n",
        "CSV_PATH     = \"dados_2h_aggregado_final.csv\"\n",
        "TARGET       = \"P_CONFLTTO_QQ_GLOBAL_SIO2\"\n",
        "TIME_COL     = \"Data\"\n",
        "CORR_THRESH  = 0.80\n",
        "TEST_SIZE    = 0.20\n",
        "VAL_SIZE     = 0.10\n",
        "RANDOM_SEED  = 42\n",
        "ES_ROUNDS    = 200\n",
        "OUTPUT_DIR   = \"outputs_feature_selection\"\n",
        "\n",
        "# MIM\n",
        "K_MIM        = 10     # quantidade de features a pegar no MIM\n",
        "MIM_N_NEIGH  = 3\n",
        "\n",
        "# Backward Selection\n",
        "BACK_MIN_FEATS        = 6      # mínimo de features ao parar\n",
        "BACK_MAX_STEPS        = 50     # segurança\n",
        "BACK_CANDIDATES_PER_STEP = 5   # avalia remover dentre as 5 piores por importância\n",
        "BACK_MIN_IMPROVEMENT  = 0.0    # exige melhora (<= atual - 0)\n",
        "\n",
        "# GroupFS\n",
        "GROUPFS_MAX_GROUPS    = None   # None = até não melhorar mais\n",
        "GROUPFS_MIN_IMPROV    = 0.0\n",
        "\n",
        "# =========================\n",
        "# Utils\n",
        "# =========================\n",
        "def read_csv_safely(path):\n",
        "    last_err = None\n",
        "    for enc in (\"utf-8\", \"latin1\", \"cp1252\"):\n",
        "        try:\n",
        "            return pd.read_csv(path, sep=None, engine=\"python\", encoding=enc)\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    raise RuntimeError(f\"Falha ao abrir {path}. Último erro: {last_err}\")\n",
        "\n",
        "\n",
        "def greedy_corr_filter(X_num: pd.DataFrame, thresh: float = 0.8):\n",
        "    \"\"\"\n",
        "    Remove colunas altamente correlacionadas (|corr| > thresh).\n",
        "    Critério: remove a variável com maior média de |corr| com as demais.\n",
        "    \"\"\"\n",
        "    corr = X_num.corr().abs()\n",
        "    ativos = set(corr.columns)\n",
        "    removidos = set()\n",
        "    while True:\n",
        "        cols = sorted(ativos)\n",
        "        if len(cols) <= 1:\n",
        "            break\n",
        "        sub = corr.loc[cols, cols].copy()\n",
        "        np.fill_diagonal(sub.values, 0.0)\n",
        "        if sub.values.size == 0:\n",
        "            break\n",
        "        max_val = sub.values.max()\n",
        "        if max_val <= thresh:\n",
        "            break\n",
        "        i, j = np.unravel_index(np.argmax(sub.values), sub.shape)\n",
        "        vi, vj = cols[i], cols[j]\n",
        "        to_remove = vi if sub[vi].mean() >= sub[vj].mean() else vj\n",
        "        ativos.remove(to_remove)\n",
        "        removidos.add(to_remove)\n",
        "    return sorted(ativos), sorted(removidos)\n",
        "\n",
        "\n",
        "def make_xgb(**overrides):\n",
        "    params = dict(\n",
        "        n_estimators=10000,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=RANDOM_SEED,\n",
        "        n_jobs=-1,\n",
        "        tree_method=\"hist\",\n",
        "        objective=\"reg:squarederror\",\n",
        "        eval_metric=\"rmse\",\n",
        "        early_stopping_rounds=ES_ROUNDS,\n",
        "    )\n",
        "    params.update(overrides)\n",
        "    return XGBRegressor(**params)\n",
        "\n",
        "\n",
        "def fit_es_and_mae(X_tr, y_tr, X_val, y_val, features):\n",
        "    \"\"\"Treina XGB com ES e retorna (modelo, mae_val).\"\"\"\n",
        "    model = make_xgb()\n",
        "    model.fit(X_tr[features], y_tr, eval_set=[(X_val[features], y_val)], verbose=False)\n",
        "    pred_val = model.predict(X_val[features])\n",
        "    mae = mean_absolute_error(y_val, pred_val)\n",
        "    return model, mae\n",
        "\n",
        "\n",
        "def rank_features_by_gain(model, feature_names):\n",
        "    \"\"\"Extrai importância por 'gain'. Se não disponível, cai em feature_importances_.\"\"\"\n",
        "    booster = model.get_booster()\n",
        "    try:\n",
        "        gain = booster.get_score(importance_type=\"gain\")  # {'f0': gain0, ...}\n",
        "        scores = [gain.get(f\"f{j}\", 0.0) for j in range(len(feature_names))]\n",
        "    except Exception:\n",
        "        scores = list(getattr(model, \"feature_importances_\", np.zeros(len(feature_names))))\n",
        "    df_imp = pd.DataFrame({\"feature\": feature_names, \"gain\": scores})\n",
        "    df_imp = df_imp.sort_values(\"gain\", ascending=False).reset_index(drop=True)\n",
        "    return df_imp\n",
        "\n",
        "\n",
        "def select_MIM(X_tr: pd.DataFrame, y_tr: pd.Series, k: int, n_neighbors: int = 3):\n",
        "    Xn = X_tr.values\n",
        "    yn = y_tr.values\n",
        "    scores = mutual_info_regression(Xn, yn, n_neighbors=n_neighbors, random_state=RANDOM_SEED)\n",
        "    df = pd.DataFrame({\"feature\": X_tr.columns, \"mi\": scores}).sort_values(\"mi\", ascending=False)\n",
        "    chosen = df.head(k)[\"feature\"].tolist()\n",
        "    return chosen, df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def backward_selection(X_tr: pd.DataFrame, y_tr: pd.Series,\n",
        "                       X_val: pd.DataFrame, y_val: pd.Series,\n",
        "                       start_features: list,\n",
        "                       min_features: int = BACK_MIN_FEATS,\n",
        "                       candidates_per_step: int = BACK_CANDIDATES_PER_STEP,\n",
        "                       max_steps: int = BACK_MAX_STEPS,\n",
        "                       min_improvement: float = BACK_MIN_IMPROVEMENT):\n",
        "    \"\"\"Greedy backward (remove 1 por step escolhendo entre as piores importâncias).\n",
        "    Retorna (selected_features, histórico)\"\"\"\n",
        "    feats = list(start_features)\n",
        "    history = []\n",
        "\n",
        "    # baseline\n",
        "    base_model, base_mae = fit_es_and_mae(X_tr, y_tr, X_val, y_val, feats)\n",
        "    history.append({\"step\": 0, \"features\": len(feats), \"removed\": None, \"val_mae\": base_mae})\n",
        "\n",
        "    step = 1\n",
        "    cur_mae = base_mae\n",
        "\n",
        "    while len(feats) > min_features and step <= max_steps:\n",
        "        # importância no conjunto atual\n",
        "        imp_df = rank_features_by_gain(base_model, feats)\n",
        "        candidates = list(imp_df.tail(min(candidates_per_step, len(feats)-min_features))['feature'])\n",
        "\n",
        "        best_remove = None\n",
        "        best_mae = cur_mae\n",
        "\n",
        "        for f in candidates:\n",
        "            tmp_feats = [x for x in feats if x != f]\n",
        "            _, mae = fit_es_and_mae(X_tr, y_tr, X_val, y_val, tmp_feats)\n",
        "            if mae <= best_mae - min_improvement:\n",
        "                best_mae = mae\n",
        "                best_remove = f\n",
        "\n",
        "        if best_remove is None:\n",
        "            break\n",
        "\n",
        "        feats.remove(best_remove)\n",
        "        cur_mae = best_mae\n",
        "        base_model, _ = fit_es_and_mae(X_tr, y_tr, X_val, y_val, feats)\n",
        "        history.append({\"step\": step, \"features\": len(feats), \"removed\": best_remove, \"val_mae\": cur_mae})\n",
        "        step += 1\n",
        "\n",
        "    return feats, pd.DataFrame(history)\n",
        "\n",
        "\n",
        "def group_key(name: str) -> str:\n",
        "    \"\"\"Define o grupo pela família após 'TO_': ex.: TO_AI..., TO_SIMF..., TO_MF..., etc.\"\"\"\n",
        "    m = re.match(r\"^TO_([A-Z]+)\", name)\n",
        "    return m.group(1) if m else \"UNGROUPED\"\n",
        "\n",
        "\n",
        "def groupfs_forward(X_tr: pd.DataFrame, y_tr: pd.Series,\n",
        "                    X_val: pd.DataFrame, y_val: pd.Series,\n",
        "                    feature_names: list,\n",
        "                    max_groups: int | None = GROUPFS_MAX_GROUPS,\n",
        "                    min_improvement: float = GROUPFS_MIN_IMPROV):\n",
        "    \"\"\"Seleciona grupos por forward greedy adicionando o grupo que mais melhora MAE.\"\"\"\n",
        "    # monta dict grupo -> lista de features\n",
        "    groups = {}\n",
        "    for f in feature_names:\n",
        "        g = group_key(f)\n",
        "        groups.setdefault(g, []).append(f)\n",
        "\n",
        "    remaining = set(groups.keys())\n",
        "    selected_groups = []\n",
        "    selected_feats = []\n",
        "\n",
        "    # primeiro passo: escolher melhor grupo isolado\n",
        "    best_g = None\n",
        "    best_mae = float('inf')\n",
        "    for g in sorted(remaining):\n",
        "        feats = groups[g]\n",
        "        _, mae = fit_es_and_mae(X_tr, y_tr, X_val, y_val, feats)\n",
        "        if mae < best_mae:\n",
        "            best_mae = mae\n",
        "            best_g = g\n",
        "    selected_groups.append(best_g)\n",
        "    selected_feats = list(groups[best_g])\n",
        "    remaining.remove(best_g)\n",
        "\n",
        "    history = [{\"step\": 1, \"added_group\": best_g, \"n_groups\": 1, \"n_features\": len(selected_feats), \"val_mae\": best_mae}]\n",
        "\n",
        "    step = 2\n",
        "    while len(remaining) > 0 and (max_groups is None or len(selected_groups) < max_groups):\n",
        "        curr_mae = history[-1][\"val_mae\"]\n",
        "        best_g = None\n",
        "        best_mae_step = curr_mae\n",
        "\n",
        "        for g in sorted(remaining):\n",
        "            feats = selected_feats + groups[g]\n",
        "            _, mae = fit_es_and_mae(X_tr, y_tr, X_val, y_val, feats)\n",
        "            if mae <= best_mae_step - min_improvement:\n",
        "                best_mae_step = mae\n",
        "                best_g = g\n",
        "\n",
        "        if best_g is None:\n",
        "            break\n",
        "\n",
        "        selected_groups.append(best_g)\n",
        "        selected_feats += groups[best_g]\n",
        "        remaining.remove(best_g)\n",
        "        history.append({\"step\": step, \"added_group\": best_g, \"n_groups\": len(selected_groups),\n",
        "                        \"n_features\": len(selected_feats), \"val_mae\": best_mae_step})\n",
        "        step += 1\n",
        "\n",
        "    return selected_feats, pd.DataFrame(history), groups\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 1) Ler dados & preparar base\n",
        "# =========================\n",
        "df = read_csv_safely(CSV_PATH)\n",
        "if TARGET not in df.columns:\n",
        "    raise ValueError(f\"Coluna alvo '{TARGET}' não encontrada no CSV.\")\n",
        "\n",
        "# alvo numérico\n",
        "y = pd.to_numeric(df[TARGET], errors=\"coerce\")\n",
        "mask_y = y.notna()\n",
        "df = df.loc[mask_y].reset_index(drop=True)\n",
        "y  = y.loc[mask_y].reset_index(drop=True)\n",
        "\n",
        "# features candidatas (remove prefixo 'P' e a própria coluna alvo)\n",
        "feature_candidates = [c for c in df.columns if not c.startswith(\"P\") and c != TARGET]\n",
        "X = df[feature_candidates].dropna(axis=1, how=\"all\").select_dtypes(include=[np.number]).copy()\n",
        "\n",
        "# filtro de correlação (colinearidade)\n",
        "kept_cols, removed_cols = greedy_corr_filter(X, CORR_THRESH)\n",
        "X = X[kept_cols].copy()\n",
        "print(f\"Features finais após filtro de correlação (|corr|>{CORR_THRESH}): {X.shape[1]} | Removidas: {len(removed_cols)}\")\n",
        "\n",
        "# split temporal\n",
        "time_sorted = False\n",
        "if TIME_COL in df.columns:\n",
        "    order = pd.to_datetime(df[TIME_COL], errors=\"coerce\")\n",
        "    if order.notna().mean() > 0.5:\n",
        "        idx = order.argsort(kind=\"mergesort\")\n",
        "        X = X.iloc[idx].reset_index(drop=True)\n",
        "        y = y.iloc[idx].reset_index(drop=True)\n",
        "        time_sorted = True\n",
        "\n",
        "# Holdout de teste (temporal se possível)\n",
        "if time_sorted:\n",
        "    cut = int((1 - TEST_SIZE) * len(X))\n",
        "    X_train, X_test = X.iloc[:cut], X.iloc[cut:]\n",
        "    y_train, y_test = y.iloc[:cut], y.iloc[cut:]\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED\n",
        "    )\n",
        "\n",
        "# Split interno (train -> train_in + val_in) para ES\n",
        "if time_sorted:\n",
        "    cut_in = int((1 - VAL_SIZE) * len(X_train))\n",
        "    X_tr_in, X_val_in = X_train.iloc[:cut_in], X_train.iloc[cut_in:]\n",
        "    y_tr_in, y_val_in = y_train.iloc[:cut_in], y_train.iloc[cut_in:]\n",
        "else:\n",
        "    X_tr_in, X_val_in, y_tr_in, y_val_in = train_test_split(\n",
        "        X_train, y_train, test_size=VAL_SIZE, random_state=RANDOM_SEED\n",
        "    )\n",
        "\n",
        "# imputação (usada como DataFrame para manter colunas)\n",
        "imp = SimpleImputer(strategy=\"median\")\n",
        "X_tr_in = pd.DataFrame(imp.fit_transform(X_tr_in), columns=X_tr_in.columns, index=X_tr_in.index).astype(np.float32)\n",
        "X_val_in = pd.DataFrame(imp.transform(X_val_in), columns=X_val_in.columns, index=X_val_in.index).astype(np.float32)\n",
        "X_train_imp = pd.DataFrame(imp.transform(X_train), columns=X_train.columns, index=X_train.index).astype(np.float32)\n",
        "X_test_imp  = pd.DataFrame(imp.transform(X_test),  columns=X_test.columns,  index=X_test.index ).astype(np.float32)\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# 2) MIM\n",
        "# =========================\n",
        "K_mim = min(K_MIM, X_tr_in.shape[1])\n",
        "mim_features, mim_rank = select_MIM(X_tr_in, y_tr_in, k=K_mim, n_neighbors=MIM_N_NEIGH)\n",
        "\n",
        "m_mim, val_mae_mim = fit_es_and_mae(X_tr_in, y_tr_in, X_val_in, y_val_in, mim_features)\n",
        "# Refit em todo o treino (treino+val) usando nova validação interna temporal (10%)\n",
        "cut_refit = int((1 - VAL_SIZE) * len(X_train_imp))\n",
        "X_refit_tr, X_refit_val = X_train_imp.iloc[:cut_refit], X_train_imp.iloc[cut_refit:]\n",
        "y_refit_tr, y_refit_val = y_train.iloc[:cut_refit], y_train.iloc[cut_refit:]\n",
        "mm = make_xgb()\n",
        "mm.fit(X_refit_tr[mim_features], y_refit_tr, eval_set=[(X_refit_val[mim_features], y_refit_val)], verbose=False)\n",
        "pred_test_mim = mm.predict(X_test_imp[mim_features])\n",
        "rmse_mim = np.sqrt(mean_squared_error(y_test, pred_test_mim))\n",
        "mae_mim  = mean_absolute_error(y_test, pred_test_mim)\n",
        "r2_mim   = r2_score(y_test, pred_test_mim)\n",
        "\n",
        "# =========================\n",
        "# 3) Backward Selection\n",
        "# =========================\n",
        "start_feats = list(X_tr_in.columns)\n",
        "b_feats, b_hist = backward_selection(\n",
        "    X_tr_in, y_tr_in, X_val_in, y_val_in, start_feats,\n",
        "    min_features=BACK_MIN_FEATS,\n",
        "    candidates_per_step=BACK_CANDIDATES_PER_STEP,\n",
        "    max_steps=BACK_MAX_STEPS,\n",
        "    min_improvement=BACK_MIN_IMPROVEMENT,\n",
        ")\n",
        "# Refit e teste\n",
        "mb = make_xgb()\n",
        "mb.fit(X_refit_tr[b_feats], y_refit_tr, eval_set=[(X_refit_val[b_feats], y_refit_val)], verbose=False)\n",
        "pred_test_back = mb.predict(X_test_imp[b_feats])\n",
        "rmse_back = np.sqrt(mean_squared_error(y_test, pred_test_back))\n",
        "mae_back  = mean_absolute_error(y_test, pred_test_back)\n",
        "r2_back   = r2_score(y_test, pred_test_back)\n",
        "\n",
        "# =========================\n",
        "# 4) GroupFS (por família TO_...)\n",
        "# =========================\n",
        "g_feats, g_hist, groups_map = groupfs_forward(\n",
        "    X_tr_in, y_tr_in, X_val_in, y_val_in, feature_names=list(X_tr_in.columns),\n",
        "    max_groups=GROUPFS_MAX_GROUPS, min_improvement=GROUPFS_MIN_IMPROV\n",
        ")\n",
        "mg = make_xgb()\n",
        "mg.fit(X_refit_tr[g_feats], y_refit_tr, eval_set=[(X_refit_val[g_feats], y_refit_val)], verbose=False)\n",
        "pred_test_group = mg.predict(X_test_imp[g_feats])\n",
        "rmse_group = np.sqrt(mean_squared_error(y_test, pred_test_group))\n",
        "mae_group  = mean_absolute_error(y_test, pred_test_group)\n",
        "r2_group   = r2_score(y_test, pred_test_group)\n",
        "\n",
        "# =========================\n",
        "# 5) Relatórios / salvamento\n",
        "# =========================\n",
        "summary = pd.DataFrame([\n",
        "    {\"method\": \"MIM\",     \"val_mae\": float(val_mae_mim),  \"test_RMSE\": float(rmse_mim),   \"test_MAE\": float(mae_mim),  \"test_R2\": float(r2_mim),  \"n_feats\": len(mim_features)},\n",
        "    {\"method\": \"Backward\", \"val_mae\": float(b_hist.iloc[-1]['val_mae']), \"test_RMSE\": float(rmse_back),  \"test_MAE\": float(mae_back), \"test_R2\": float(r2_back), \"n_feats\": len(b_feats)},\n",
        "    {\"method\": \"GroupFS\",  \"val_mae\": float(g_hist.iloc[-1]['val_mae']), \"test_RMSE\": float(rmse_group), \"test_MAE\": float(mae_group),\"test_R2\": float(r2_group),\"n_feats\": len(g_feats)},\n",
        "]).sort_values(\"test_MAE\").reset_index(drop=True)\n",
        "\n",
        "mim_rank.to_csv(os.path.join(OUTPUT_DIR, \"mim_ranking.csv\"), index=False, encoding=\"utf-8\")\n",
        "pd.Series(mim_features).to_csv(os.path.join(OUTPUT_DIR, \"mim_selected_features.txt\"), index=False, header=False)\n",
        "\n",
        "b_hist.to_csv(os.path.join(OUTPUT_DIR, \"backward_history.csv\"), index=False, encoding=\"utf-8\")\n",
        "pd.Series(b_feats).to_csv(os.path.join(OUTPUT_DIR, \"backward_selected_features.txt\"), index=False, header=False)\n",
        "\n",
        "g_hist.to_csv(os.path.join(OUTPUT_DIR, \"groupfs_history.csv\"), index=False, encoding=\"utf-8\")\n",
        "pd.Series(g_feats).to_csv(os.path.join(OUTPUT_DIR, \"groupfs_selected_features.txt\"), index=False, header=False)\n",
        "\n",
        "with open(os.path.join(OUTPUT_DIR, \"groupfs_groups_map.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    for g, feats in sorted(groups_map.items()):\n",
        "        f.write(f\"[{g}]\\n\")\n",
        "        for ft in feats:\n",
        "            f.write(f\"  - {ft}\\n\")\n",
        "\n",
        "summary.to_csv(os.path.join(OUTPUT_DIR, \"summary_metrics.csv\"), index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n================= RESULTADOS (Teste Holdout) =================\")\n",
        "print(summary)\n",
        "print(\"==========================================================\\n\")\n",
        "\n",
        "print(f\"Arquivos salvos em: {OUTPUT_DIR}\")\n",
        "print(\"- mim_ranking.csv | mim_selected_features.txt\")\n",
        "print(\"- backward_history.csv | backward_selected_features.txt\")\n",
        "print(\"- groupfs_history.csv | groupfs_selected_features.txt | groupfs_groups_map.txt\")\n",
        "print(\"- summary_metrics.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gnnpHDmjqjm"
      },
      "outputs": [],
      "source": [
        "Backward = [\n",
        "    \"TO_AI6401_01\", \"TO_AI6402_01\", \"TO_BO6311_EST1\", \"TO_DI6311_01\", \"TO_FI6311_01\",\n",
        "    \"TO_FI8271_01\", \"TO_FY6104_01\", \"TO_LI6401_01\", \"TO_LI6401_02\", \"TO_LI6402_01\",\n",
        "    \"TO_LI6411_01\", \"TO_LI6411_02\", \"TO_LI6412_01\", \"TO_LI6412_02\", \"TO_LI6431_01\",\n",
        "    \"TO_LI6432_01\", \"TO_MF6401_M1_EST1\", \"TO_MF6402_M1_EST1\", \"TO_MF6411_M1_EST1\",\n",
        "    \"TO_MF6412_M1_EST1\", \"TO_MF6421_M1_EST1\", \"TO_PHY4804_02\", \"TO_PHY4814_02\",\n",
        "    \"TO_SIMF640101\", \"TO_SIMF640102\", \"TO_SIMF640201\", \"TO_SIMF640202\", \"TO_SIMF641101\",\n",
        "    \"TO_SIMF641102\", \"TO_SIMF641201\", \"TO_SIMF641202\", \"TO_SIMF6421\", \"TO_SIMF6422\",\n",
        "    \"TO_SIMF6431\", \"TO_SIMF6432\", \"TO_WI4804_01\"\n",
        "]\n",
        "\n",
        "groups = [\n",
        "    \"TO_WI4804_01\", \"TO_FY6104_01\", \"TO_AI6401_01\", \"TO_AI6402_01\", \"TO_BO6311_EST1\"\n",
        "]\n",
        "\n",
        "mim = [\n",
        "    \"TO_SIMF6432\", \"TO_SIMF6431\", \"TO_PHY4804_02\", \"TO_SIMF641201\", \"TO_SIMF6421\",\n",
        "    \"TO_SIMF640101\", \"TO_PHY4814_02\", \"TO_SIMF6422\", \"TO_WI4804_01\", \"TO_SIMF640202\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F2iDXcG6i3i"
      },
      "source": [
        "Runs the models in multiple iterations specified by the user.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvlG3iSSms5w",
        "outputId": "08d3cf6c-cf26-41e7-e0c1-3c85b127be2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "[INFO] Z-score |z|<=3.0: mantidas 7,060 / 7,244 linhas\n",
            "================================================================================\n",
            "Rodando feature sets: feature1, feature2, feature3, feature4, feature5, feature6, feature7\n",
            "\n",
            "--- [feature1] Iniciando (36 variáveis, 7060 linhas após Z-score) ---\n",
            "[feature1] primeiras variáveis: TO_AI6401_01, TO_AI6402_01, TO_BO6311_EST1, TO_DI6311_01, TO_FI6311_01...\n",
            "[feature1][run 01/20] split: train=5,648 | test=1,412 | seed=89250\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 01] RF: RMSE=1.2918 R2=0.2396 MAE=0.8944 | DT: RMSE=1.4582 R2=0.0311 MAE=1.0215 | ADA: RMSE=1.4560 R2=0.0341 MAE=1.1708 | XGB: RMSE=1.2467 R2=0.2918 MAE=0.8312 | LGBM: RMSE=1.2731 R2=0.2615 MAE=0.8456 | MLP: RMSE=1.3462 R2=0.1742 MAE=0.9495 | NAIVE: RMSE=1.4815 R2=-0.0001 MAE=1.0747   (56.62s)\n",
            "[feature1][run 02/20] split: train=5,648 | test=1,412 | seed=773956\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 02] RF: RMSE=1.2450 R2=0.2361 MAE=0.8619 | DT: RMSE=1.3903 R2=0.0473 MAE=0.9825 | ADA: RMSE=1.4037 R2=0.0290 MAE=1.1458 | XGB: RMSE=1.1921 R2=0.2996 MAE=0.8044 | LGBM: RMSE=1.1859 R2=0.3069 MAE=0.8049 | MLP: RMSE=1.3107 R2=0.1533 MAE=0.9116 | NAIVE: RMSE=1.4251 R2=-0.0009 MAE=1.0432   (55.19s)\n",
            "[feature1][run 03/20] split: train=5,648 | test=1,412 | seed=654571\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 03] RF: RMSE=1.3611 R2=0.2225 MAE=0.9062 | DT: RMSE=1.5243 R2=0.0247 MAE=1.0290 | ADA: RMSE=1.5012 R2=0.0541 MAE=1.1836 | XGB: RMSE=1.3210 R2=0.2675 MAE=0.8414 | LGBM: RMSE=1.3313 R2=0.2560 MAE=0.8522 | MLP: RMSE=1.4322 R2=0.1391 MAE=0.9543 | NAIVE: RMSE=1.5438 R2=-0.0004 MAE=1.0874   (57.06s)\n",
            "[feature1][run 04/20] split: train=5,648 | test=1,412 | seed=438878\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 04] RF: RMSE=1.3007 R2=0.2539 MAE=0.8812 | DT: RMSE=1.4805 R2=0.0334 MAE=1.0180 | ADA: RMSE=1.4498 R2=0.0730 MAE=1.1544 | XGB: RMSE=1.2569 R2=0.3034 MAE=0.8272 | LGBM: RMSE=1.2573 R2=0.3029 MAE=0.8280 | MLP: RMSE=1.3668 R2=0.1762 MAE=0.9277 | NAIVE: RMSE=1.5064 R2=-0.0007 MAE=1.0724   (56.92s)\n",
            "[feature1][run 05/20] split: train=5,648 | test=1,412 | seed=433015\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 05] RF: RMSE=1.3257 R2=0.2304 MAE=0.8833 | DT: RMSE=1.4543 R2=0.0739 MAE=1.0038 | ADA: RMSE=1.4595 R2=0.0673 MAE=1.1389 | XGB: RMSE=1.2774 R2=0.2854 MAE=0.8293 | LGBM: RMSE=1.2816 R2=0.2807 MAE=0.8394 | MLP: RMSE=1.3839 R2=0.1614 MAE=0.9238 | NAIVE: RMSE=1.5118 R2=-0.0008 MAE=1.0641   (55.30s)\n",
            "[feature1][run 06/20] split: train=5,648 | test=1,412 | seed=858597\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 06] RF: RMSE=1.2338 R2=0.2599 MAE=0.8640 | DT: RMSE=1.4147 R2=0.0270 MAE=0.9974 | ADA: RMSE=1.4325 R2=0.0024 MAE=1.1666 | XGB: RMSE=1.1745 R2=0.3294 MAE=0.8010 | LGBM: RMSE=1.1743 R2=0.3296 MAE=0.8121 | MLP: RMSE=1.3014 R2=0.1766 MAE=0.9141 | NAIVE: RMSE=1.4346 R2=-0.0005 MAE=1.0330   (58.06s)\n",
            "[feature1][run 07/20] split: train=5,648 | test=1,412 | seed=85945\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 07] RF: RMSE=1.2495 R2=0.2564 MAE=0.8548 | DT: RMSE=1.3944 R2=0.0740 MAE=0.9734 | ADA: RMSE=1.4254 R2=0.0323 MAE=1.1393 | XGB: RMSE=1.1968 R2=0.3178 MAE=0.8009 | LGBM: RMSE=1.2112 R2=0.3013 MAE=0.8109 | MLP: RMSE=1.3277 R2=0.1604 MAE=0.9141 | NAIVE: RMSE=1.4491 R2=-0.0001 MAE=1.0303   (56.57s)\n",
            "[feature1][run 08/20] split: train=5,648 | test=1,412 | seed=697368\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 08] RF: RMSE=1.2445 R2=0.2642 MAE=0.8559 | DT: RMSE=1.4101 R2=0.0552 MAE=0.9756 | ADA: RMSE=1.4237 R2=0.0369 MAE=1.1631 | XGB: RMSE=1.1901 R2=0.3271 MAE=0.7865 | LGBM: RMSE=1.2022 R2=0.3133 MAE=0.7973 | MLP: RMSE=1.3032 R2=0.1930 MAE=0.8955 | NAIVE: RMSE=1.4520 R2=-0.0017 MAE=1.0492   (57.39s)\n",
            "[feature1][run 09/20] split: train=5,648 | test=1,412 | seed=201469\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 09] RF: RMSE=1.2602 R2=0.2349 MAE=0.8840 | DT: RMSE=1.4320 R2=0.0121 MAE=1.0213 | ADA: RMSE=1.4453 R2=-0.0063 MAE=1.1884 | XGB: RMSE=1.2147 R2=0.2892 MAE=0.8230 | LGBM: RMSE=1.2337 R2=0.2668 MAE=0.8433 | MLP: RMSE=1.3162 R2=0.1654 MAE=0.9077 | NAIVE: RMSE=1.4414 R2=-0.0008 MAE=1.0538   (55.97s)\n",
            "[feature1][run 10/20] split: train=5,648 | test=1,412 | seed=94177\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 10] RF: RMSE=1.2079 R2=0.2379 MAE=0.8475 | DT: RMSE=1.3619 R2=0.0313 MAE=0.9692 | ADA: RMSE=1.4001 R2=-0.0239 MAE=1.1411 | XGB: RMSE=1.1528 R2=0.3059 MAE=0.7868 | LGBM: RMSE=1.1668 R2=0.2889 MAE=0.8030 | MLP: RMSE=1.2601 R2=0.1706 MAE=0.8844 | NAIVE: RMSE=1.3853 R2=-0.0023 MAE=1.0158   (58.00s)\n",
            "[feature1][run 11/20] split: train=5,648 | test=1,412 | seed=526478\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 11] RF: RMSE=1.3385 R2=0.2061 MAE=0.9069 | DT: RMSE=1.4920 R2=0.0135 MAE=1.0304 | ADA: RMSE=1.4878 R2=0.0190 MAE=1.1833 | XGB: RMSE=1.2986 R2=0.2527 MAE=0.8553 | LGBM: RMSE=1.3036 R2=0.2469 MAE=0.8648 | MLP: RMSE=1.3988 R2=0.1329 MAE=0.9365 | NAIVE: RMSE=1.5024 R2=-0.0002 MAE=1.0673   (56.15s)\n",
            "[feature1][run 12/20] split: train=5,648 | test=1,412 | seed=975622\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 12] RF: RMSE=1.2535 R2=0.2736 MAE=0.8636 | DT: RMSE=1.3913 R2=0.1050 MAE=0.9652 | ADA: RMSE=1.4476 R2=0.0311 MAE=1.1729 | XGB: RMSE=1.2099 R2=0.3232 MAE=0.8107 | LGBM: RMSE=1.2087 R2=0.3246 MAE=0.8117 | MLP: RMSE=1.3252 R2=0.1881 MAE=0.9067 | NAIVE: RMSE=1.4717 R2=-0.0014 MAE=1.0512   (57.11s)\n",
            "[feature1][run 13/20] split: train=5,648 | test=1,412 | seed=735752\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 13] RF: RMSE=1.3268 R2=0.2245 MAE=0.8881 | DT: RMSE=1.4845 R2=0.0292 MAE=1.0277 | ADA: RMSE=1.4710 R2=0.0468 MAE=1.1546 | XGB: RMSE=1.2841 R2=0.2736 MAE=0.8306 | LGBM: RMSE=1.2779 R2=0.2805 MAE=0.8295 | MLP: RMSE=1.3719 R2=0.1708 MAE=0.9328 | NAIVE: RMSE=1.5067 R2=-0.0000 MAE=1.0687   (54.80s)\n",
            "[feature1][run 14/20] split: train=5,648 | test=1,412 | seed=761139\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 14] RF: RMSE=1.2959 R2=0.2261 MAE=0.8801 | DT: RMSE=1.4629 R2=0.0137 MAE=1.0122 | ADA: RMSE=1.4468 R2=0.0353 MAE=1.1443 | XGB: RMSE=1.2617 R2=0.2664 MAE=0.8241 | LGBM: RMSE=1.2743 R2=0.2517 MAE=0.8335 | MLP: RMSE=1.3802 R2=0.1221 MAE=0.9228 | NAIVE: RMSE=1.4732 R2=-0.0002 MAE=1.0623   (57.84s)\n",
            "[feature1][run 15/20] split: train=5,648 | test=1,412 | seed=717477\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 15] RF: RMSE=1.3442 R2=0.2420 MAE=0.9174 | DT: RMSE=1.4908 R2=0.0677 MAE=1.0345 | ADA: RMSE=1.4926 R2=0.0654 MAE=1.1973 | XGB: RMSE=1.3009 R2=0.2901 MAE=0.8574 | LGBM: RMSE=1.3062 R2=0.2842 MAE=0.8670 | MLP: RMSE=1.3724 R2=0.2099 MAE=0.9310 | NAIVE: RMSE=1.5440 R2=-0.0001 MAE=1.1093   (56.74s)\n",
            "[feature1][run 16/20] split: train=5,648 | test=1,412 | seed=786064\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 16] RF: RMSE=1.3387 R2=0.2251 MAE=0.9075 | DT: RMSE=1.4892 R2=0.0412 MAE=1.0265 | ADA: RMSE=1.4852 R2=0.0463 MAE=1.1754 | XGB: RMSE=1.2883 R2=0.2824 MAE=0.8535 | LGBM: RMSE=1.2796 R2=0.2921 MAE=0.8572 | MLP: RMSE=1.4021 R2=0.1500 MAE=0.9805 | NAIVE: RMSE=1.5211 R2=-0.0005 MAE=1.0695   (55.07s)\n",
            "[feature1][run 17/20] split: train=5,648 | test=1,412 | seed=513226\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 17] RF: RMSE=1.2699 R2=0.2441 MAE=0.8712 | DT: RMSE=1.4333 R2=0.0370 MAE=1.0042 | ADA: RMSE=1.4461 R2=0.0197 MAE=1.1635 | XGB: RMSE=1.2284 R2=0.2926 MAE=0.8163 | LGBM: RMSE=1.2307 R2=0.2900 MAE=0.8263 | MLP: RMSE=1.3470 R2=0.1495 MAE=0.9344 | NAIVE: RMSE=1.4608 R2=-0.0004 MAE=1.0485   (56.72s)\n",
            "[feature1][run 18/20] split: train=5,648 | test=1,412 | seed=128113\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 18] RF: RMSE=1.2907 R2=0.2371 MAE=0.8672 | DT: RMSE=1.4743 R2=0.0046 MAE=1.0048 | ADA: RMSE=1.4401 R2=0.0503 MAE=1.1370 | XGB: RMSE=1.2529 R2=0.2811 MAE=0.8262 | LGBM: RMSE=1.2620 R2=0.2706 MAE=0.8389 | MLP: RMSE=1.3433 R2=0.1736 MAE=0.9041 | NAIVE: RMSE=1.4780 R2=-0.0003 MAE=1.0362   (58.35s)\n",
            "[feature1][run 19/20] split: train=5,648 | test=1,412 | seed=839748\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 19] RF: RMSE=1.2765 R2=0.2368 MAE=0.8710 | DT: RMSE=1.4359 R2=0.0343 MAE=1.0062 | ADA: RMSE=1.4325 R2=0.0388 MAE=1.1600 | XGB: RMSE=1.2309 R2=0.2903 MAE=0.8149 | LGBM: RMSE=1.2318 R2=0.2892 MAE=0.8212 | MLP: RMSE=1.3374 R2=0.1621 MAE=0.9430 | NAIVE: RMSE=1.4612 R2=-0.0001 MAE=1.0483   (56.89s)\n",
            "[feature1][run 20/20] split: train=5,648 | test=1,412 | seed=450385\n",
            "[feature1] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature1.json\n",
            "[feature1] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature1] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature1] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature1] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature1] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature1] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature1][run 20] RF: RMSE=1.2999 R2=0.2560 MAE=0.8829 | DT: RMSE=1.4701 R2=0.0484 MAE=1.0200 | ADA: RMSE=1.4646 R2=0.0555 MAE=1.1682 | XGB: RMSE=1.2503 R2=0.3117 MAE=0.8300 | LGBM: RMSE=1.2378 R2=0.3254 MAE=0.8294 | MLP: RMSE=1.3580 R2=0.1880 MAE=0.9244 | NAIVE: RMSE=1.5070 R2=-0.0000 MAE=1.0677   (55.67s)\n",
            "[feature1] Resumo (média ± desvio) nas 20 runs:\n",
            "  NAIVE | RMSE=1.4778±0.0397 | R2=-0.0006±0.0006 | MAE=1.0576±0.0208\n",
            "  DT    | RMSE=1.4472±0.0420 | R2=0.0402±0.0243 | MAE=1.0062±0.0216\n",
            "  RF    | RMSE=1.2877±0.0412 | R2=0.2404±0.0160 | MAE=0.8795±0.0191\n",
            "  ADA   | RMSE=1.4506±0.0270 | R2=0.0354±0.0240 | MAE=1.1624±0.0175\n",
            "  XGB   | RMSE=1.2415±0.0451 | R2=0.2941±0.0204 | MAE=0.8225±0.0199\n",
            "  LGBM  | RMSE=1.2465±0.0446 | R2=0.2882±0.0240 | MAE=0.8308±0.0199\n",
            "  MLP   | RMSE=1.3492±0.0399 | R2=0.1659±0.0206 | MAE=0.9250±0.0214\n",
            "[feature1] Tempo total: 1132.42s\n",
            "\n",
            "\n",
            "--- [feature2] Iniciando (10 variáveis, 7060 linhas após Z-score) ---\n",
            "[feature2] primeiras variáveis: TO_WI4804_01, TO_PHY4814_02, TO_PHY4804_02, TO_SIMF641201, TO_LI6412_01...\n",
            "[feature2][run 01/20] split: train=5,648 | test=1,412 | seed=89250\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 01] RF: RMSE=1.3125 R2=0.2150 MAE=0.9063 | DT: RMSE=1.4489 R2=0.0434 MAE=1.0205 | ADA: RMSE=1.5012 R2=-0.0269 MAE=1.2092 | XGB: RMSE=1.3157 R2=0.2112 MAE=0.9035 | LGBM: RMSE=1.3308 R2=0.1931 MAE=0.9128 | MLP: RMSE=1.3863 R2=0.1243 MAE=0.9680 | NAIVE: RMSE=1.4815 R2=-0.0001 MAE=1.0747   (26.70s)\n",
            "[feature2][run 02/20] split: train=5,648 | test=1,412 | seed=773956\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 02] RF: RMSE=1.2691 R2=0.2062 MAE=0.8763 | DT: RMSE=1.4055 R2=0.0264 MAE=0.9895 | ADA: RMSE=1.4674 R2=-0.0612 MAE=1.2036 | XGB: RMSE=1.2553 R2=0.2233 MAE=0.8692 | LGBM: RMSE=1.2736 R2=0.2006 MAE=0.8905 | MLP: RMSE=1.3042 R2=0.1617 MAE=0.9067 | NAIVE: RMSE=1.4251 R2=-0.0009 MAE=1.0432   (27.57s)\n",
            "[feature2][run 03/20] split: train=5,648 | test=1,412 | seed=654571\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 03] RF: RMSE=1.3805 R2=0.2000 MAE=0.9153 | DT: RMSE=1.5051 R2=0.0492 MAE=1.0255 | ADA: RMSE=1.5494 R2=-0.0076 MAE=1.2302 | XGB: RMSE=1.3810 R2=0.1995 MAE=0.9127 | LGBM: RMSE=1.3932 R2=0.1853 MAE=0.9336 | MLP: RMSE=1.4475 R2=0.1206 MAE=0.9662 | NAIVE: RMSE=1.5438 R2=-0.0004 MAE=1.0874   (32.95s)\n",
            "[feature2][run 04/20] split: train=5,648 | test=1,412 | seed=438878\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 04] RF: RMSE=1.2973 R2=0.2578 MAE=0.8775 | DT: RMSE=1.4814 R2=0.0322 MAE=1.0303 | ADA: RMSE=1.5108 R2=-0.0065 MAE=1.2188 | XGB: RMSE=1.3096 R2=0.2437 MAE=0.8849 | LGBM: RMSE=1.3213 R2=0.2302 MAE=0.8959 | MLP: RMSE=1.3752 R2=0.1660 MAE=0.9614 | NAIVE: RMSE=1.5064 R2=-0.0007 MAE=1.0724   (30.32s)\n",
            "[feature2][run 05/20] split: train=5,648 | test=1,412 | seed=433015\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 05] RF: RMSE=1.3409 R2=0.2126 MAE=0.8960 | DT: RMSE=1.4546 R2=0.0735 MAE=1.0038 | ADA: RMSE=1.5201 R2=-0.0118 MAE=1.1957 | XGB: RMSE=1.3377 R2=0.2164 MAE=0.8933 | LGBM: RMSE=1.3398 R2=0.2140 MAE=0.9040 | MLP: RMSE=1.4243 R2=0.1117 MAE=0.9653 | NAIVE: RMSE=1.5118 R2=-0.0008 MAE=1.0641   (28.37s)\n",
            "[feature2][run 06/20] split: train=5,648 | test=1,412 | seed=858597\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 06] RF: RMSE=1.2698 R2=0.2161 MAE=0.8818 | DT: RMSE=1.4156 R2=0.0258 MAE=1.0061 | ADA: RMSE=1.4828 R2=-0.0689 MAE=1.2011 | XGB: RMSE=1.2781 R2=0.2058 MAE=0.8761 | LGBM: RMSE=1.2904 R2=0.1905 MAE=0.8868 | MLP: RMSE=1.3673 R2=0.0911 MAE=0.9624 | NAIVE: RMSE=1.4346 R2=-0.0005 MAE=1.0330   (24.62s)\n",
            "[feature2][run 07/20] split: train=5,648 | test=1,412 | seed=85945\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 07] RF: RMSE=1.2789 R2=0.2209 MAE=0.8716 | DT: RMSE=1.4242 R2=0.0340 MAE=0.9903 | ADA: RMSE=1.4714 R2=-0.0312 MAE=1.1709 | XGB: RMSE=1.2686 R2=0.2335 MAE=0.8646 | LGBM: RMSE=1.2884 R2=0.2094 MAE=0.8823 | MLP: RMSE=1.3338 R2=0.1527 MAE=0.9480 | NAIVE: RMSE=1.4491 R2=-0.0001 MAE=1.0303   (32.03s)\n",
            "[feature2][run 08/20] split: train=5,648 | test=1,412 | seed=697368\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 08] RF: RMSE=1.2885 R2=0.2111 MAE=0.8820 | DT: RMSE=1.4012 R2=0.0671 MAE=0.9898 | ADA: RMSE=1.4884 R2=-0.0526 MAE=1.2079 | XGB: RMSE=1.2961 R2=0.2019 MAE=0.8820 | LGBM: RMSE=1.3249 R2=0.1660 MAE=0.9077 | MLP: RMSE=1.3762 R2=0.1001 MAE=0.9428 | NAIVE: RMSE=1.4520 R2=-0.0017 MAE=1.0492   (36.10s)\n",
            "[feature2][run 09/20] split: train=5,648 | test=1,412 | seed=201469\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 09] RF: RMSE=1.2839 R2=0.2059 MAE=0.8868 | DT: RMSE=1.4174 R2=0.0322 MAE=0.9879 | ADA: RMSE=1.4835 R2=-0.0601 MAE=1.2123 | XGB: RMSE=1.3013 R2=0.1843 MAE=0.8980 | LGBM: RMSE=1.3203 R2=0.1602 MAE=0.9031 | MLP: RMSE=1.3534 R2=0.1176 MAE=0.9527 | NAIVE: RMSE=1.4414 R2=-0.0008 MAE=1.0538   (30.22s)\n",
            "[feature2][run 10/20] split: train=5,648 | test=1,412 | seed=94177\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 10] RF: RMSE=1.2280 R2=0.2123 MAE=0.8647 | DT: RMSE=1.3738 R2=0.0143 MAE=0.9897 | ADA: RMSE=1.4408 R2=-0.0843 MAE=1.1796 | XGB: RMSE=1.2292 R2=0.2108 MAE=0.8658 | LGBM: RMSE=1.2475 R2=0.1872 MAE=0.8823 | MLP: RMSE=1.3028 R2=0.1136 MAE=0.9481 | NAIVE: RMSE=1.3853 R2=-0.0023 MAE=1.0158   (33.01s)\n",
            "[feature2][run 11/20] split: train=5,648 | test=1,412 | seed=526478\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 11] RF: RMSE=1.3495 R2=0.1930 MAE=0.9228 | DT: RMSE=1.4741 R2=0.0370 MAE=1.0332 | ADA: RMSE=1.5297 R2=-0.0370 MAE=1.2186 | XGB: RMSE=1.3519 R2=0.1901 MAE=0.9172 | LGBM: RMSE=1.3666 R2=0.1724 MAE=0.9261 | MLP: RMSE=1.4154 R2=0.1122 MAE=0.9528 | NAIVE: RMSE=1.5024 R2=-0.0002 MAE=1.0673   (27.57s)\n",
            "[feature2][run 12/20] split: train=5,648 | test=1,412 | seed=975622\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 12] RF: RMSE=1.2928 R2=0.2272 MAE=0.8784 | DT: RMSE=1.4529 R2=0.0240 MAE=1.0184 | ADA: RMSE=1.5089 R2=-0.0527 MAE=1.2193 | XGB: RMSE=1.3113 R2=0.2050 MAE=0.8908 | LGBM: RMSE=1.3268 R2=0.1862 MAE=0.9111 | MLP: RMSE=1.3598 R2=0.1451 MAE=0.9518 | NAIVE: RMSE=1.4717 R2=-0.0014 MAE=1.0512   (28.00s)\n",
            "[feature2][run 13/20] split: train=5,648 | test=1,412 | seed=735752\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 13] RF: RMSE=1.3633 R2=0.1813 MAE=0.9076 | DT: RMSE=1.4969 R2=0.0129 MAE=1.0217 | ADA: RMSE=1.5287 R2=-0.0295 MAE=1.2089 | XGB: RMSE=1.3714 R2=0.1715 MAE=0.9034 | LGBM: RMSE=1.3966 R2=0.1408 MAE=0.9179 | MLP: RMSE=1.4329 R2=0.0955 MAE=0.9662 | NAIVE: RMSE=1.5067 R2=-0.0000 MAE=1.0687   (28.27s)\n",
            "[feature2][run 14/20] split: train=5,648 | test=1,412 | seed=761139\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 14] RF: RMSE=1.3221 R2=0.1944 MAE=0.8947 | DT: RMSE=1.4778 R2=-0.0065 MAE=1.0181 | ADA: RMSE=1.4981 R2=-0.0343 MAE=1.1952 | XGB: RMSE=1.3253 R2=0.1906 MAE=0.8909 | LGBM: RMSE=1.3428 R2=0.1690 MAE=0.9154 | MLP: RMSE=1.3854 R2=0.1154 MAE=0.9631 | NAIVE: RMSE=1.4732 R2=-0.0002 MAE=1.0623   (30.56s)\n",
            "[feature2][run 15/20] split: train=5,648 | test=1,412 | seed=717477\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 15] RF: RMSE=1.3651 R2=0.2182 MAE=0.9280 | DT: RMSE=1.5122 R2=0.0406 MAE=1.0597 | ADA: RMSE=1.5577 R2=-0.0179 MAE=1.2542 | XGB: RMSE=1.3756 R2=0.2062 MAE=0.9388 | LGBM: RMSE=1.3890 R2=0.1907 MAE=0.9511 | MLP: RMSE=1.4310 R2=0.1410 MAE=1.0244 | NAIVE: RMSE=1.5440 R2=-0.0001 MAE=1.1093   (30.44s)\n",
            "[feature2][run 16/20] split: train=5,648 | test=1,412 | seed=786064\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 16] RF: RMSE=1.3513 R2=0.2105 MAE=0.9109 | DT: RMSE=1.4994 R2=0.0279 MAE=1.0394 | ADA: RMSE=1.5344 R2=-0.0179 MAE=1.2187 | XGB: RMSE=1.3395 R2=0.2241 MAE=0.9007 | LGBM: RMSE=1.3385 R2=0.2253 MAE=0.9090 | MLP: RMSE=1.4293 R2=0.1167 MAE=0.9643 | NAIVE: RMSE=1.5211 R2=-0.0005 MAE=1.0695   (31.10s)\n",
            "[feature2][run 17/20] split: train=5,648 | test=1,412 | seed=513226\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 17] RF: RMSE=1.2737 R2=0.2395 MAE=0.8734 | DT: RMSE=1.4402 R2=0.0277 MAE=0.9837 | ADA: RMSE=1.4859 R2=-0.0350 MAE=1.1954 | XGB: RMSE=1.2656 R2=0.2491 MAE=0.8642 | LGBM: RMSE=1.2631 R2=0.2521 MAE=0.8684 | MLP: RMSE=1.3635 R2=0.1284 MAE=0.9572 | NAIVE: RMSE=1.4608 R2=-0.0004 MAE=1.0485   (30.06s)\n",
            "[feature2][run 18/20] split: train=5,648 | test=1,412 | seed=128113\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 18] RF: RMSE=1.3299 R2=0.1901 MAE=0.8872 | DT: RMSE=1.4376 R2=0.0535 MAE=0.9865 | ADA: RMSE=1.4940 R2=-0.0222 MAE=1.1766 | XGB: RMSE=1.3330 R2=0.1863 MAE=0.9012 | LGBM: RMSE=1.3509 R2=0.1643 MAE=0.9185 | MLP: RMSE=1.3934 R2=0.1109 MAE=0.9599 | NAIVE: RMSE=1.4780 R2=-0.0003 MAE=1.0362   (28.71s)\n",
            "[feature2][run 19/20] split: train=5,648 | test=1,412 | seed=839748\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 19] RF: RMSE=1.2888 R2=0.2220 MAE=0.8815 | DT: RMSE=1.4284 R2=0.0442 MAE=0.9938 | ADA: RMSE=1.4873 R2=-0.0361 MAE=1.2030 | XGB: RMSE=1.2934 R2=0.2164 MAE=0.8852 | LGBM: RMSE=1.2990 R2=0.2096 MAE=0.8853 | MLP: RMSE=1.3619 R2=0.1312 MAE=0.9451 | NAIVE: RMSE=1.4612 R2=-0.0001 MAE=1.0483   (28.77s)\n",
            "[feature2][run 20/20] split: train=5,648 | test=1,412 | seed=450385\n",
            "[feature2] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature2.json\n",
            "[feature2] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature2] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature2] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature2] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature2] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature2] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature2][run 20] RF: RMSE=1.3035 R2=0.2518 MAE=0.8877 | DT: RMSE=1.4794 R2=0.0363 MAE=1.0404 | ADA: RMSE=1.5288 R2=-0.0291 MAE=1.2205 | XGB: RMSE=1.3039 R2=0.2513 MAE=0.8923 | LGBM: RMSE=1.3143 R2=0.2394 MAE=0.8950 | MLP: RMSE=1.3810 R2=0.1602 MAE=0.9739 | NAIVE: RMSE=1.5070 R2=-0.0000 MAE=1.0677   (30.95s)\n",
            "[feature2] Resumo (média ± desvio) nas 20 runs:\n",
            "  NAIVE | RMSE=1.4778±0.0397 | R2=-0.0006±0.0006 | MAE=1.0576±0.0208\n",
            "  DT    | RMSE=1.4513±0.0378 | R2=0.0348±0.0177 | MAE=1.0114±0.0218\n",
            "  RF    | RMSE=1.3095±0.0387 | R2=0.2143±0.0189 | MAE=0.8915±0.0175\n",
            "  ADA   | RMSE=1.5035±0.0286 | R2=-0.0361±0.0206 | MAE=1.2070±0.0187\n",
            "  XGB   | RMSE=1.3122±0.0400 | R2=0.2111±0.0213 | MAE=0.8917±0.0186\n",
            "  LGBM  | RMSE=1.3259±0.0405 | R2=0.1943±0.0279 | MAE=0.9048±0.0193\n",
            "  MLP   | RMSE=1.3812±0.0397 | R2=0.1258±0.0215 | MAE=0.9590±0.0204\n",
            "[feature2] Tempo total: 596.33s\n",
            "\n",
            "\n",
            "--- [feature3] Iniciando (10 variáveis, 7060 linhas após Z-score) ---\n",
            "[feature3] primeiras variáveis: TO_MF6412_M1_EST1, TO_FI8271_01, TO_PHY4814_02, TO_WI4804_01, TO_SIMF6421...\n",
            "[feature3][run 01/20] split: train=5,648 | test=1,412 | seed=89250\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 01] RF: RMSE=1.3213 R2=0.2045 MAE=0.9146 | DT: RMSE=1.4381 R2=0.0577 MAE=1.0091 | ADA: RMSE=1.4639 R2=0.0235 MAE=1.1389 | XGB: RMSE=1.3050 R2=0.2240 MAE=0.8855 | LGBM: RMSE=1.3175 R2=0.2091 MAE=0.8901 | MLP: RMSE=1.3642 R2=0.1520 MAE=0.9831 | NAIVE: RMSE=1.4815 R2=-0.0001 MAE=1.0747   (20.73s)\n",
            "[feature3][run 02/20] split: train=5,648 | test=1,412 | seed=773956\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 02] RF: RMSE=1.2813 R2=0.1909 MAE=0.8826 | DT: RMSE=1.4366 R2=-0.0171 MAE=1.0257 | ADA: RMSE=1.4251 R2=-0.0009 MAE=1.1368 | XGB: RMSE=1.2514 R2=0.2283 MAE=0.8489 | LGBM: RMSE=1.2531 R2=0.2262 MAE=0.8571 | MLP: RMSE=1.3298 R2=0.1285 MAE=0.9047 | NAIVE: RMSE=1.4251 R2=-0.0009 MAE=1.0432   (23.11s)\n",
            "[feature3][run 03/20] split: train=5,648 | test=1,412 | seed=654571\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 03] RF: RMSE=1.3842 R2=0.1958 MAE=0.9220 | DT: RMSE=1.4877 R2=0.0711 MAE=1.0243 | ADA: RMSE=1.4825 R2=0.0775 MAE=1.1341 | XGB: RMSE=1.3659 R2=0.2169 MAE=0.8842 | LGBM: RMSE=1.3757 R2=0.2056 MAE=0.8955 | MLP: RMSE=1.4577 R2=0.1081 MAE=0.9995 | NAIVE: RMSE=1.5438 R2=-0.0004 MAE=1.0874   (20.55s)\n",
            "[feature3][run 04/20] split: train=5,648 | test=1,412 | seed=438878\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 04] RF: RMSE=1.3221 R2=0.2292 MAE=0.8943 | DT: RMSE=1.4775 R2=0.0373 MAE=1.0119 | ADA: RMSE=1.5081 R2=-0.0029 MAE=1.1679 | XGB: RMSE=1.3068 R2=0.2469 MAE=0.8669 | LGBM: RMSE=1.3141 R2=0.2385 MAE=0.8719 | MLP: RMSE=1.4158 R2=0.1160 MAE=0.9689 | NAIVE: RMSE=1.5064 R2=-0.0007 MAE=1.0724   (21.42s)\n",
            "[feature3][run 05/20] split: train=5,648 | test=1,412 | seed=433015\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 05] RF: RMSE=1.3480 R2=0.2043 MAE=0.8985 | DT: RMSE=1.5177 R2=-0.0086 MAE=1.0425 | ADA: RMSE=1.4908 R2=0.0268 MAE=1.1317 | XGB: RMSE=1.3396 R2=0.2142 MAE=0.8876 | LGBM: RMSE=1.3471 R2=0.2053 MAE=0.8977 | MLP: RMSE=1.4086 R2=0.1312 MAE=0.9513 | NAIVE: RMSE=1.5118 R2=-0.0008 MAE=1.0641   (20.67s)\n",
            "[feature3][run 06/20] split: train=5,648 | test=1,412 | seed=858597\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 06] RF: RMSE=1.2657 R2=0.2212 MAE=0.8786 | DT: RMSE=1.4074 R2=0.0371 MAE=0.9893 | ADA: RMSE=1.4609 R2=-0.0376 MAE=1.1562 | XGB: RMSE=1.2473 R2=0.2437 MAE=0.8527 | LGBM: RMSE=1.2489 R2=0.2418 MAE=0.8568 | MLP: RMSE=1.3215 R2=0.1510 MAE=0.9117 | NAIVE: RMSE=1.4346 R2=-0.0005 MAE=1.0330   (22.89s)\n",
            "[feature3][run 07/20] split: train=5,648 | test=1,412 | seed=85945\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 07] RF: RMSE=1.2860 R2=0.2123 MAE=0.8803 | DT: RMSE=1.4127 R2=0.0495 MAE=0.9875 | ADA: RMSE=1.4308 R2=0.0250 MAE=1.1113 | XGB: RMSE=1.2607 R2=0.2430 MAE=0.8535 | LGBM: RMSE=1.2675 R2=0.2348 MAE=0.8611 | MLP: RMSE=1.3630 R2=0.1151 MAE=0.9295 | NAIVE: RMSE=1.4491 R2=-0.0001 MAE=1.0303   (21.28s)\n",
            "[feature3][run 08/20] split: train=5,648 | test=1,412 | seed=697368\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 08] RF: RMSE=1.2646 R2=0.2401 MAE=0.8658 | DT: RMSE=1.3967 R2=0.0731 MAE=0.9835 | ADA: RMSE=1.4574 R2=-0.0092 MAE=1.1570 | XGB: RMSE=1.2501 R2=0.2574 MAE=0.8366 | LGBM: RMSE=1.2611 R2=0.2443 MAE=0.8434 | MLP: RMSE=1.3281 R2=0.1620 MAE=0.9037 | NAIVE: RMSE=1.4520 R2=-0.0017 MAE=1.0492   (21.26s)\n",
            "[feature3][run 09/20] split: train=5,648 | test=1,412 | seed=201469\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 09] RF: RMSE=1.2895 R2=0.1990 MAE=0.8954 | DT: RMSE=1.4409 R2=-0.0002 MAE=1.0252 | ADA: RMSE=1.4206 R2=0.0279 MAE=1.1279 | XGB: RMSE=1.2672 R2=0.2264 MAE=0.8643 | LGBM: RMSE=1.2744 R2=0.2176 MAE=0.8727 | MLP: RMSE=1.3550 R2=0.1155 MAE=0.9756 | NAIVE: RMSE=1.4414 R2=-0.0008 MAE=1.0538   (21.79s)\n",
            "[feature3][run 10/20] split: train=5,648 | test=1,412 | seed=94177\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 10] RF: RMSE=1.2349 R2=0.2036 MAE=0.8625 | DT: RMSE=1.3933 R2=-0.0139 MAE=0.9840 | ADA: RMSE=1.4555 R2=-0.1064 MAE=1.1593 | XGB: RMSE=1.2176 R2=0.2256 MAE=0.8303 | LGBM: RMSE=1.2310 R2=0.2085 MAE=0.8425 | MLP: RMSE=1.3371 R2=0.0662 MAE=0.9668 | NAIVE: RMSE=1.3853 R2=-0.0023 MAE=1.0158   (22.90s)\n",
            "[feature3][run 11/20] split: train=5,648 | test=1,412 | seed=526478\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 11] RF: RMSE=1.3421 R2=0.2018 MAE=0.9219 | DT: RMSE=1.4904 R2=0.0156 MAE=1.0436 | ADA: RMSE=1.5129 R2=-0.0143 MAE=1.1754 | XGB: RMSE=1.3113 R2=0.2380 MAE=0.8862 | LGBM: RMSE=1.3157 R2=0.2329 MAE=0.8898 | MLP: RMSE=1.4258 R2=0.0991 MAE=0.9857 | NAIVE: RMSE=1.5024 R2=-0.0002 MAE=1.0673   (23.55s)\n",
            "[feature3][run 12/20] split: train=5,648 | test=1,412 | seed=975622\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 12] RF: RMSE=1.2875 R2=0.2336 MAE=0.8858 | DT: RMSE=1.4302 R2=0.0542 MAE=1.0094 | ADA: RMSE=1.4825 R2=-0.0162 MAE=1.1603 | XGB: RMSE=1.2719 R2=0.2521 MAE=0.8619 | LGBM: RMSE=1.2710 R2=0.2531 MAE=0.8629 | MLP: RMSE=1.3579 R2=0.1475 MAE=0.9499 | NAIVE: RMSE=1.4717 R2=-0.0014 MAE=1.0512   (23.34s)\n",
            "[feature3][run 13/20] split: train=5,648 | test=1,412 | seed=735752\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 13] RF: RMSE=1.3621 R2=0.1826 MAE=0.9061 | DT: RMSE=1.4898 R2=0.0222 MAE=1.0065 | ADA: RMSE=1.4802 R2=0.0348 MAE=1.1197 | XGB: RMSE=1.3579 R2=0.1877 MAE=0.8809 | LGBM: RMSE=1.3637 R2=0.1808 MAE=0.8875 | MLP: RMSE=1.4207 R2=0.1109 MAE=0.9444 | NAIVE: RMSE=1.5067 R2=-0.0000 MAE=1.0687   (21.95s)\n",
            "[feature3][run 14/20] split: train=5,648 | test=1,412 | seed=761139\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 14] RF: RMSE=1.3058 R2=0.2142 MAE=0.8820 | DT: RMSE=1.4396 R2=0.0448 MAE=0.9869 | ADA: RMSE=1.4399 R2=0.0445 MAE=1.1151 | XGB: RMSE=1.2978 R2=0.2238 MAE=0.8640 | LGBM: RMSE=1.3076 R2=0.2120 MAE=0.8753 | MLP: RMSE=1.3623 R2=0.1447 MAE=0.9411 | NAIVE: RMSE=1.4732 R2=-0.0002 MAE=1.0623   (21.35s)\n",
            "[feature3][run 15/20] split: train=5,648 | test=1,412 | seed=717477\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 15] RF: RMSE=1.3604 R2=0.2236 MAE=0.9350 | DT: RMSE=1.4820 R2=0.0786 MAE=1.0377 | ADA: RMSE=1.5441 R2=-0.0002 MAE=1.2312 | XGB: RMSE=1.3411 R2=0.2455 MAE=0.9085 | LGBM: RMSE=1.3395 R2=0.2473 MAE=0.9109 | MLP: RMSE=1.4417 R2=0.1281 MAE=0.9983 | NAIVE: RMSE=1.5440 R2=-0.0001 MAE=1.1093   (21.04s)\n",
            "[feature3][run 16/20] split: train=5,648 | test=1,412 | seed=786064\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 16] RF: RMSE=1.3513 R2=0.2104 MAE=0.9172 | DT: RMSE=1.5283 R2=-0.0099 MAE=1.0445 | ADA: RMSE=1.4996 R2=0.0277 MAE=1.1658 | XGB: RMSE=1.3143 R2=0.2531 MAE=0.8894 | LGBM: RMSE=1.3121 R2=0.2556 MAE=0.8938 | MLP: RMSE=1.4131 R2=0.1367 MAE=0.9412 | NAIVE: RMSE=1.5211 R2=-0.0005 MAE=1.0695   (23.20s)\n",
            "[feature3][run 17/20] split: train=5,648 | test=1,412 | seed=513226\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 17] RF: RMSE=1.2974 R2=0.2110 MAE=0.8851 | DT: RMSE=1.4173 R2=0.0584 MAE=0.9766 | ADA: RMSE=1.4776 R2=-0.0234 MAE=1.1623 | XGB: RMSE=1.2845 R2=0.2265 MAE=0.8669 | LGBM: RMSE=1.2936 R2=0.2156 MAE=0.8736 | MLP: RMSE=1.3662 R2=0.1250 MAE=0.9327 | NAIVE: RMSE=1.4608 R2=-0.0004 MAE=1.0485   (22.67s)\n",
            "[feature3][run 18/20] split: train=5,648 | test=1,412 | seed=128113\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 18] RF: RMSE=1.3189 R2=0.2034 MAE=0.8791 | DT: RMSE=1.4572 R2=0.0276 MAE=0.9999 | ADA: RMSE=1.4742 R2=0.0048 MAE=1.1482 | XGB: RMSE=1.2888 R2=0.2394 MAE=0.8632 | LGBM: RMSE=1.2955 R2=0.2315 MAE=0.8718 | MLP: RMSE=1.3867 R2=0.1194 MAE=0.9572 | NAIVE: RMSE=1.4780 R2=-0.0003 MAE=1.0362   (20.70s)\n",
            "[feature3][run 19/20] split: train=5,648 | test=1,412 | seed=839748\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 19] RF: RMSE=1.2837 R2=0.2282 MAE=0.8861 | DT: RMSE=1.4226 R2=0.0521 MAE=0.9864 | ADA: RMSE=1.4463 R2=0.0202 MAE=1.1468 | XGB: RMSE=1.2751 R2=0.2384 MAE=0.8663 | LGBM: RMSE=1.2822 R2=0.2299 MAE=0.8730 | MLP: RMSE=1.3799 R2=0.1081 MAE=0.9541 | NAIVE: RMSE=1.4612 R2=-0.0001 MAE=1.0483   (22.51s)\n",
            "[feature3][run 20/20] split: train=5,648 | test=1,412 | seed=450385\n",
            "[feature3] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature3.json\n",
            "[feature3] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature3] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature3] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature3] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature3] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature3] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature3][run 20] RF: RMSE=1.3121 R2=0.2420 MAE=0.8973 | DT: RMSE=1.4421 R2=0.0843 MAE=0.9944 | ADA: RMSE=1.4889 R2=0.0239 MAE=1.1438 | XGB: RMSE=1.2907 R2=0.2665 MAE=0.8710 | LGBM: RMSE=1.2920 R2=0.2651 MAE=0.8775 | MLP: RMSE=1.3987 R2=0.1386 MAE=0.9613 | NAIVE: RMSE=1.5070 R2=-0.0000 MAE=1.0677   (20.79s)\n",
            "[feature3] Resumo (média ± desvio) nas 20 runs:\n",
            "  NAIVE | RMSE=1.4778±0.0397 | R2=-0.0006±0.0006 | MAE=1.0576±0.0208\n",
            "  DT    | RMSE=1.4504±0.0382 | R2=0.0357±0.0316 | MAE=1.0084±0.0220\n",
            "  RF    | RMSE=1.3109±0.0375 | R2=0.2126±0.0159 | MAE=0.8945±0.0191\n",
            "  ADA   | RMSE=1.4721±0.0307 | R2=0.0063±0.0365 | MAE=1.1495±0.0258\n",
            "  XGB   | RMSE=1.2923±0.0381 | R2=0.2349±0.0174 | MAE=0.8684±0.0185\n",
            "  LGBM  | RMSE=1.2982±0.0378 | R2=0.2278±0.0204 | MAE=0.8752±0.0177\n",
            "  MLP   | RMSE=1.3817±0.0386 | R2=0.1252±0.0215 | MAE=0.9530±0.0274\n",
            "[feature3] Tempo total: 437.70s\n",
            "\n",
            "\n",
            "--- [feature4] Iniciando (20 variáveis, 7060 linhas após Z-score) ---\n",
            "[feature4] primeiras variáveis: TO_PHY4804_02, TO_AI6401_01, TO_AI6402_01, TO_LI6412_01, TO_LI6412_02...\n",
            "[feature4][run 01/20] split: train=5,648 | test=1,412 | seed=89250\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 01] RF: RMSE=1.2863 R2=0.2461 MAE=0.8892 | DT: RMSE=1.4665 R2=0.0201 MAE=1.0380 | ADA: RMSE=1.4010 R2=0.1056 MAE=1.0829 | XGB: RMSE=1.2673 R2=0.2682 MAE=0.8516 | LGBM: RMSE=1.2850 R2=0.2476 MAE=0.8592 | MLP: RMSE=1.3557 R2=0.1625 MAE=0.9310 | NAIVE: RMSE=1.4815 R2=-0.0001 MAE=1.0747   (41.44s)\n",
            "[feature4][run 02/20] split: train=5,648 | test=1,412 | seed=773956\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 02] RF: RMSE=1.2453 R2=0.2357 MAE=0.8577 | DT: RMSE=1.4141 R2=0.0144 MAE=1.0138 | ADA: RMSE=1.3616 R2=0.0863 MAE=1.0625 | XGB: RMSE=1.2255 R2=0.2599 MAE=0.8327 | LGBM: RMSE=1.2193 R2=0.2672 MAE=0.8290 | MLP: RMSE=1.2860 R2=0.1849 MAE=0.8856 | NAIVE: RMSE=1.4251 R2=-0.0009 MAE=1.0432   (39.18s)\n",
            "[feature4][run 03/20] split: train=5,648 | test=1,412 | seed=654571\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 03] RF: RMSE=1.3597 R2=0.2240 MAE=0.9069 | DT: RMSE=1.5029 R2=0.0520 MAE=1.0529 | ADA: RMSE=1.4646 R2=0.0996 MAE=1.1072 | XGB: RMSE=1.3441 R2=0.2417 MAE=0.8664 | LGBM: RMSE=1.3521 R2=0.2327 MAE=0.8754 | MLP: RMSE=1.4359 R2=0.1346 MAE=0.9462 | NAIVE: RMSE=1.5438 R2=-0.0004 MAE=1.0874   (36.13s)\n",
            "[feature4][run 04/20] split: train=5,648 | test=1,412 | seed=438878\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 04] RF: RMSE=1.2831 R2=0.2739 MAE=0.8716 | DT: RMSE=1.4399 R2=0.0857 MAE=1.0113 | ADA: RMSE=1.3962 R2=0.1404 MAE=1.0684 | XGB: RMSE=1.2664 R2=0.2927 MAE=0.8471 | LGBM: RMSE=1.2690 R2=0.2898 MAE=0.8516 | MLP: RMSE=1.3662 R2=0.1769 MAE=0.9272 | NAIVE: RMSE=1.5064 R2=-0.0007 MAE=1.0724   (37.48s)\n",
            "[feature4][run 05/20] split: train=5,648 | test=1,412 | seed=433015\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 05] RF: RMSE=1.3188 R2=0.2384 MAE=0.8753 | DT: RMSE=1.4766 R2=0.0452 MAE=1.0139 | ADA: RMSE=1.4225 R2=0.1139 MAE=1.0613 | XGB: RMSE=1.2746 R2=0.2886 MAE=0.8358 | LGBM: RMSE=1.2831 R2=0.2790 MAE=0.8481 | MLP: RMSE=1.3774 R2=0.1693 MAE=0.9427 | NAIVE: RMSE=1.5118 R2=-0.0008 MAE=1.0641   (36.12s)\n",
            "[feature4][run 06/20] split: train=5,648 | test=1,412 | seed=858597\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 06] RF: RMSE=1.2261 R2=0.2692 MAE=0.8605 | DT: RMSE=1.3968 R2=0.0515 MAE=1.0118 | ADA: RMSE=1.3692 R2=0.0886 MAE=1.0721 | XGB: RMSE=1.2036 R2=0.2958 MAE=0.8231 | LGBM: RMSE=1.2044 R2=0.2947 MAE=0.8299 | MLP: RMSE=1.3287 R2=0.1418 MAE=0.9368 | NAIVE: RMSE=1.4346 R2=-0.0005 MAE=1.0330   (36.69s)\n",
            "[feature4][run 07/20] split: train=5,648 | test=1,412 | seed=85945\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 07] RF: RMSE=1.2453 R2=0.2614 MAE=0.8533 | DT: RMSE=1.4105 R2=0.0524 MAE=0.9874 | ADA: RMSE=1.3725 R2=0.1027 MAE=1.0509 | XGB: RMSE=1.2224 R2=0.2883 MAE=0.8258 | LGBM: RMSE=1.2361 R2=0.2723 MAE=0.8379 | MLP: RMSE=1.3034 R2=0.1908 MAE=0.8884 | NAIVE: RMSE=1.4491 R2=-0.0001 MAE=1.0303   (38.33s)\n",
            "[feature4][run 08/20] split: train=5,648 | test=1,412 | seed=697368\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 08] RF: RMSE=1.2469 R2=0.2613 MAE=0.8588 | DT: RMSE=1.4200 R2=0.0419 MAE=1.0001 | ADA: RMSE=1.3721 R2=0.1055 MAE=1.0747 | XGB: RMSE=1.2171 R2=0.2961 MAE=0.8154 | LGBM: RMSE=1.2264 R2=0.2853 MAE=0.8263 | MLP: RMSE=1.3288 R2=0.1610 MAE=0.9228 | NAIVE: RMSE=1.4520 R2=-0.0017 MAE=1.0492   (37.94s)\n",
            "[feature4][run 09/20] split: train=5,648 | test=1,412 | seed=201469\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 09] RF: RMSE=1.2702 R2=0.2227 MAE=0.8891 | DT: RMSE=1.3914 R2=0.0674 MAE=0.9960 | ADA: RMSE=1.3964 R2=0.0607 MAE=1.1015 | XGB: RMSE=1.2592 R2=0.2361 MAE=0.8613 | LGBM: RMSE=1.2548 R2=0.2415 MAE=0.8659 | MLP: RMSE=1.3322 R2=0.1450 MAE=0.9270 | NAIVE: RMSE=1.4414 R2=-0.0008 MAE=1.0538   (37.62s)\n",
            "[feature4][run 10/20] split: train=5,648 | test=1,412 | seed=94177\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 10] RF: RMSE=1.2161 R2=0.2276 MAE=0.8504 | DT: RMSE=1.3652 R2=0.0266 MAE=0.9819 | ADA: RMSE=1.3530 R2=0.0439 MAE=1.0613 | XGB: RMSE=1.1853 R2=0.2662 MAE=0.8138 | LGBM: RMSE=1.2073 R2=0.2388 MAE=0.8282 | MLP: RMSE=1.2788 R2=0.1459 MAE=0.9095 | NAIVE: RMSE=1.3853 R2=-0.0023 MAE=1.0158   (36.63s)\n",
            "[feature4][run 11/20] split: train=5,648 | test=1,412 | seed=526478\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 11] RF: RMSE=1.3430 R2=0.2008 MAE=0.9050 | DT: RMSE=1.4744 R2=0.0366 MAE=1.0331 | ADA: RMSE=1.4441 R2=0.0759 MAE=1.0975 | XGB: RMSE=1.3322 R2=0.2135 MAE=0.8759 | LGBM: RMSE=1.3234 R2=0.2238 MAE=0.8767 | MLP: RMSE=1.3928 R2=0.1404 MAE=0.9664 | NAIVE: RMSE=1.5024 R2=-0.0002 MAE=1.0673   (40.75s)\n",
            "[feature4][run 12/20] split: train=5,648 | test=1,412 | seed=975622\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 12] RF: RMSE=1.2477 R2=0.2802 MAE=0.8604 | DT: RMSE=1.4334 R2=0.0501 MAE=1.0069 | ADA: RMSE=1.3866 R2=0.1111 MAE=1.0757 | XGB: RMSE=1.2501 R2=0.2775 MAE=0.8475 | LGBM: RMSE=1.2475 R2=0.2804 MAE=0.8436 | MLP: RMSE=1.3154 R2=0.2000 MAE=0.9082 | NAIVE: RMSE=1.4717 R2=-0.0014 MAE=1.0512   (36.69s)\n",
            "[feature4][run 13/20] split: train=5,648 | test=1,412 | seed=735752\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 13] RF: RMSE=1.3276 R2=0.2236 MAE=0.8828 | DT: RMSE=1.4590 R2=0.0622 MAE=1.0177 | ADA: RMSE=1.4387 R2=0.0881 MAE=1.0770 | XGB: RMSE=1.3164 R2=0.2366 MAE=0.8592 | LGBM: RMSE=1.3211 R2=0.2311 MAE=0.8650 | MLP: RMSE=1.4211 R2=0.1104 MAE=0.9804 | NAIVE: RMSE=1.5067 R2=-0.0000 MAE=1.0687   (38.98s)\n",
            "[feature4][run 14/20] split: train=5,648 | test=1,412 | seed=761139\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 14] RF: RMSE=1.2876 R2=0.2359 MAE=0.8784 | DT: RMSE=1.4393 R2=0.0453 MAE=1.0100 | ADA: RMSE=1.4018 R2=0.0944 MAE=1.0653 | XGB: RMSE=1.2677 R2=0.2593 MAE=0.8454 | LGBM: RMSE=1.2760 R2=0.2497 MAE=0.8536 | MLP: RMSE=1.3562 R2=0.1523 MAE=0.9510 | NAIVE: RMSE=1.4732 R2=-0.0002 MAE=1.0623   (36.92s)\n",
            "[feature4][run 15/20] split: train=5,648 | test=1,412 | seed=717477\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 15] RF: RMSE=1.3385 R2=0.2484 MAE=0.9115 | DT: RMSE=1.5264 R2=0.0226 MAE=1.0732 | ADA: RMSE=1.4574 R2=0.1089 MAE=1.1196 | XGB: RMSE=1.3184 R2=0.2708 MAE=0.8803 | LGBM: RMSE=1.3298 R2=0.2581 MAE=0.8891 | MLP: RMSE=1.3999 R2=0.1778 MAE=0.9667 | NAIVE: RMSE=1.5440 R2=-0.0001 MAE=1.1093   (36.54s)\n",
            "[feature4][run 16/20] split: train=5,648 | test=1,412 | seed=786064\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 16] RF: RMSE=1.3399 R2=0.2238 MAE=0.9072 | DT: RMSE=1.4848 R2=0.0468 MAE=1.0152 | ADA: RMSE=1.4475 R2=0.0941 MAE=1.0944 | XGB: RMSE=1.3050 R2=0.2636 MAE=0.8780 | LGBM: RMSE=1.3129 R2=0.2547 MAE=0.8842 | MLP: RMSE=1.4060 R2=0.1452 MAE=0.9528 | NAIVE: RMSE=1.5211 R2=-0.0005 MAE=1.0695   (38.04s)\n",
            "[feature4][run 17/20] split: train=5,648 | test=1,412 | seed=513226\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 17] RF: RMSE=1.2719 R2=0.2417 MAE=0.8690 | DT: RMSE=1.4225 R2=0.0515 MAE=1.0090 | ADA: RMSE=1.3909 R2=0.0932 MAE=1.0743 | XGB: RMSE=1.2527 R2=0.2643 MAE=0.8378 | LGBM: RMSE=1.2522 R2=0.2649 MAE=0.8439 | MLP: RMSE=1.3382 R2=0.1605 MAE=0.9227 | NAIVE: RMSE=1.4608 R2=-0.0004 MAE=1.0485   (36.76s)\n",
            "[feature4][run 18/20] split: train=5,648 | test=1,412 | seed=128113\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 18] RF: RMSE=1.2915 R2=0.2361 MAE=0.8635 | DT: RMSE=1.4314 R2=0.0618 MAE=0.9925 | ADA: RMSE=1.3908 R2=0.1142 MAE=1.0516 | XGB: RMSE=1.2631 R2=0.2693 MAE=0.8462 | LGBM: RMSE=1.2682 R2=0.2634 MAE=0.8537 | MLP: RMSE=1.3911 R2=0.1138 MAE=0.9804 | NAIVE: RMSE=1.4780 R2=-0.0003 MAE=1.0362   (41.46s)\n",
            "[feature4][run 19/20] split: train=5,648 | test=1,412 | seed=839748\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 19] RF: RMSE=1.2765 R2=0.2367 MAE=0.8698 | DT: RMSE=1.4014 R2=0.0800 MAE=0.9823 | ADA: RMSE=1.3844 R2=0.1022 MAE=1.0765 | XGB: RMSE=1.2495 R2=0.2687 MAE=0.8341 | LGBM: RMSE=1.2515 R2=0.2664 MAE=0.8327 | MLP: RMSE=1.3360 R2=0.1639 MAE=0.9033 | NAIVE: RMSE=1.4612 R2=-0.0001 MAE=1.0483   (38.38s)\n",
            "[feature4][run 20/20] split: train=5,648 | test=1,412 | seed=450385\n",
            "[feature4] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature4.json\n",
            "[feature4] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature4] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature4] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature4] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature4] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature4] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature4][run 20] RF: RMSE=1.2907 R2=0.2664 MAE=0.8836 | DT: RMSE=1.4641 R2=0.0562 MAE=1.0151 | ADA: RMSE=1.4260 R2=0.1046 MAE=1.0839 | XGB: RMSE=1.2572 R2=0.3041 MAE=0.8560 | LGBM: RMSE=1.2634 R2=0.2972 MAE=0.8583 | MLP: RMSE=1.3785 R2=0.1633 MAE=0.9487 | NAIVE: RMSE=1.5070 R2=-0.0000 MAE=1.0677   (38.57s)\n",
            "[feature4] Resumo (média ± desvio) nas 20 runs:\n",
            "  NAIVE | RMSE=1.4778±0.0397 | R2=-0.0006±0.0006 | MAE=1.0576±0.0208\n",
            "  DT    | RMSE=1.4410±0.0395 | R2=0.0485±0.0181 | MAE=1.0131±0.0221\n",
            "  RF    | RMSE=1.2856±0.0403 | R2=0.2427±0.0201 | MAE=0.8772±0.0187\n",
            "  ADA   | RMSE=1.4039±0.0323 | R2=0.0967±0.0199 | MAE=1.0779±0.0179\n",
            "  XGB   | RMSE=1.2639±0.0415 | R2=0.2681±0.0226 | MAE=0.8467±0.0193\n",
            "  LGBM  | RMSE=1.2692±0.0408 | R2=0.2619±0.0213 | MAE=0.8526±0.0187\n",
            "  MLP   | RMSE=1.3564±0.0429 | R2=0.1570±0.0228 | MAE=0.9349±0.0269\n",
            "[feature4] Tempo total: 760.67s\n",
            "\n",
            "\n",
            "--- [feature5] Iniciando (36 variáveis, 7060 linhas após Z-score) ---\n",
            "[feature5] primeiras variáveis: TO_AI6401_01, TO_AI6402_01, TO_BO6311_EST1, TO_DI6311_01, TO_FI6311_01...\n",
            "[feature5][run 01/20] split: train=5,648 | test=1,412 | seed=89250\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 01] RF: RMSE=1.2885 R2=0.2436 MAE=0.8934 | DT: RMSE=1.4586 R2=0.0306 MAE=1.0359 | ADA: RMSE=1.4095 R2=0.0948 MAE=1.0503 | XGB: RMSE=1.2542 R2=0.2832 MAE=0.8403 | LGBM: RMSE=1.2621 R2=0.2742 MAE=0.8425 | MLP: RMSE=1.3304 R2=0.1935 MAE=0.9436 | NAIVE: RMSE=1.4815 R2=-0.0001 MAE=1.0747   (42.46s)\n",
            "[feature5][run 02/20] split: train=5,648 | test=1,412 | seed=773956\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 02] RF: RMSE=1.2431 R2=0.2384 MAE=0.8636 | DT: RMSE=1.3532 R2=0.0976 MAE=0.9676 | ADA: RMSE=1.3550 R2=0.0951 MAE=1.0219 | XGB: RMSE=1.1864 R2=0.3063 MAE=0.7996 | LGBM: RMSE=1.1869 R2=0.3057 MAE=0.7988 | MLP: RMSE=1.3145 R2=0.1484 MAE=0.9185 | NAIVE: RMSE=1.4251 R2=-0.0009 MAE=1.0432   (45.01s)\n",
            "[feature5][run 03/20] split: train=5,648 | test=1,412 | seed=654571\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 03] RF: RMSE=1.3583 R2=0.2257 MAE=0.9053 | DT: RMSE=1.4877 R2=0.0711 MAE=1.0219 | ADA: RMSE=1.4668 R2=0.0969 MAE=1.0731 | XGB: RMSE=1.3238 R2=0.2645 MAE=0.8432 | LGBM: RMSE=1.3242 R2=0.2640 MAE=0.8438 | MLP: RMSE=1.4673 R2=0.0963 MAE=0.9390 | NAIVE: RMSE=1.5438 R2=-0.0004 MAE=1.0874   (46.16s)\n",
            "[feature5][run 04/20] split: train=5,648 | test=1,412 | seed=438878\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 04] RF: RMSE=1.2948 R2=0.2607 MAE=0.8793 | DT: RMSE=1.4467 R2=0.0771 MAE=1.0042 | ADA: RMSE=1.4155 R2=0.1164 MAE=1.0437 | XGB: RMSE=1.2539 R2=0.3067 MAE=0.8236 | LGBM: RMSE=1.2587 R2=0.3014 MAE=0.8245 | MLP: RMSE=1.3649 R2=0.1785 MAE=0.9157 | NAIVE: RMSE=1.5064 R2=-0.0007 MAE=1.0724   (41.47s)\n",
            "[feature5][run 05/20] split: train=5,648 | test=1,412 | seed=433015\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 05] RF: RMSE=1.3235 R2=0.2330 MAE=0.8811 | DT: RMSE=1.4601 R2=0.0665 MAE=1.0128 | ADA: RMSE=1.4338 R2=0.0998 MAE=1.0342 | XGB: RMSE=1.2682 R2=0.2957 MAE=0.8278 | LGBM: RMSE=1.2842 R2=0.2778 MAE=0.8400 | MLP: RMSE=1.3860 R2=0.1588 MAE=0.9454 | NAIVE: RMSE=1.5118 R2=-0.0008 MAE=1.0641   (43.41s)\n",
            "[feature5][run 06/20] split: train=5,648 | test=1,412 | seed=858597\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 06] RF: RMSE=1.2236 R2=0.2721 MAE=0.8579 | DT: RMSE=1.4259 R2=0.0115 MAE=1.0102 | ADA: RMSE=1.3662 R2=0.0926 MAE=1.0281 | XGB: RMSE=1.1738 R2=0.3302 MAE=0.8027 | LGBM: RMSE=1.1754 R2=0.3283 MAE=0.8092 | MLP: RMSE=1.2977 R2=0.1813 MAE=0.8984 | NAIVE: RMSE=1.4346 R2=-0.0005 MAE=1.0330   (41.25s)\n",
            "[feature5][run 07/20] split: train=5,648 | test=1,412 | seed=85945\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 07] RF: RMSE=1.2478 R2=0.2584 MAE=0.8555 | DT: RMSE=1.4044 R2=0.0607 MAE=0.9673 | ADA: RMSE=1.3687 R2=0.1078 MAE=1.0096 | XGB: RMSE=1.1991 R2=0.3151 MAE=0.8021 | LGBM: RMSE=1.2052 R2=0.3082 MAE=0.8088 | MLP: RMSE=1.3224 R2=0.1670 MAE=0.9269 | NAIVE: RMSE=1.4491 R2=-0.0001 MAE=1.0303   (44.18s)\n",
            "[feature5][run 08/20] split: train=5,648 | test=1,412 | seed=697368\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 08] RF: RMSE=1.2410 R2=0.2683 MAE=0.8513 | DT: RMSE=1.4067 R2=0.0597 MAE=0.9838 | ADA: RMSE=1.3750 R2=0.1017 MAE=1.0315 | XGB: RMSE=1.1941 R2=0.3225 MAE=0.7872 | LGBM: RMSE=1.1884 R2=0.3289 MAE=0.7821 | MLP: RMSE=1.3120 R2=0.1822 MAE=0.8985 | NAIVE: RMSE=1.4520 R2=-0.0017 MAE=1.0492   (43.59s)\n",
            "[feature5][run 09/20] split: train=5,648 | test=1,412 | seed=201469\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 09] RF: RMSE=1.2547 R2=0.2417 MAE=0.8771 | DT: RMSE=1.4125 R2=0.0389 MAE=1.0215 | ADA: RMSE=1.3810 R2=0.0813 MAE=1.0515 | XGB: RMSE=1.2156 R2=0.2881 MAE=0.8239 | LGBM: RMSE=1.2125 R2=0.2917 MAE=0.8210 | MLP: RMSE=1.3130 R2=0.1695 MAE=0.9064 | NAIVE: RMSE=1.4414 R2=-0.0008 MAE=1.0538   (44.10s)\n",
            "[feature5][run 10/20] split: train=5,648 | test=1,412 | seed=94177\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 10] RF: RMSE=1.2025 R2=0.2448 MAE=0.8441 | DT: RMSE=1.3499 R2=0.0483 MAE=0.9614 | ADA: RMSE=1.3280 R2=0.0788 MAE=1.0153 | XGB: RMSE=1.1490 R2=0.3105 MAE=0.7860 | LGBM: RMSE=1.1643 R2=0.2919 MAE=0.8003 | MLP: RMSE=1.2581 R2=0.1733 MAE=0.8829 | NAIVE: RMSE=1.3853 R2=-0.0023 MAE=1.0158   (41.80s)\n",
            "[feature5][run 11/20] split: train=5,648 | test=1,412 | seed=526478\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 11] RF: RMSE=1.3317 R2=0.2141 MAE=0.9019 | DT: RMSE=1.4913 R2=0.0144 MAE=1.0410 | ADA: RMSE=1.4419 R2=0.0786 MAE=1.0583 | XGB: RMSE=1.2922 R2=0.2600 MAE=0.8575 | LGBM: RMSE=1.3066 R2=0.2434 MAE=0.8633 | MLP: RMSE=1.4055 R2=0.1246 MAE=0.9242 | NAIVE: RMSE=1.5024 R2=-0.0002 MAE=1.0673   (45.36s)\n",
            "[feature5][run 12/20] split: train=5,648 | test=1,412 | seed=975622\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 12] RF: RMSE=1.2449 R2=0.2835 MAE=0.8597 | DT: RMSE=1.4464 R2=0.0327 MAE=1.0132 | ADA: RMSE=1.3918 R2=0.1044 MAE=1.0349 | XGB: RMSE=1.2096 R2=0.3236 MAE=0.8118 | LGBM: RMSE=1.2077 R2=0.3256 MAE=0.8154 | MLP: RMSE=1.3250 R2=0.1883 MAE=0.9159 | NAIVE: RMSE=1.4717 R2=-0.0014 MAE=1.0512   (45.82s)\n",
            "[feature5][run 13/20] split: train=5,648 | test=1,412 | seed=735752\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 13] RF: RMSE=1.3240 R2=0.2278 MAE=0.8867 | DT: RMSE=1.4760 R2=0.0402 MAE=1.0235 | ADA: RMSE=1.4336 R2=0.0946 MAE=1.0462 | XGB: RMSE=1.2745 R2=0.2844 MAE=0.8262 | LGBM: RMSE=1.2833 R2=0.2746 MAE=0.8331 | MLP: RMSE=1.4125 R2=0.1210 MAE=0.9530 | NAIVE: RMSE=1.5067 R2=-0.0000 MAE=1.0687   (42.09s)\n",
            "[feature5][run 14/20] split: train=5,648 | test=1,412 | seed=761139\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 14] RF: RMSE=1.2939 R2=0.2284 MAE=0.8775 | DT: RMSE=1.4306 R2=0.0568 MAE=1.0113 | ADA: RMSE=1.3983 R2=0.0989 MAE=1.0374 | XGB: RMSE=1.2625 R2=0.2654 MAE=0.8270 | LGBM: RMSE=1.2692 R2=0.2576 MAE=0.8374 | MLP: RMSE=1.3519 R2=0.1577 MAE=0.8941 | NAIVE: RMSE=1.4732 R2=-0.0002 MAE=1.0623   (44.96s)\n",
            "[feature5][run 15/20] split: train=5,648 | test=1,412 | seed=717477\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 15] RF: RMSE=1.3374 R2=0.2496 MAE=0.9109 | DT: RMSE=1.5059 R2=0.0487 MAE=1.0801 | ADA: RMSE=1.4611 R2=0.1045 MAE=1.0780 | XGB: RMSE=1.2960 R2=0.2954 MAE=0.8586 | LGBM: RMSE=1.3048 R2=0.2859 MAE=0.8675 | MLP: RMSE=1.3635 R2=0.2201 MAE=0.9226 | NAIVE: RMSE=1.5440 R2=-0.0001 MAE=1.1093   (41.24s)\n",
            "[feature5][run 16/20] split: train=5,648 | test=1,412 | seed=786064\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 16] RF: RMSE=1.3354 R2=0.2289 MAE=0.9038 | DT: RMSE=1.4994 R2=0.0279 MAE=1.0420 | ADA: RMSE=1.4476 R2=0.0940 MAE=1.0598 | XGB: RMSE=1.2750 R2=0.2971 MAE=0.8496 | LGBM: RMSE=1.2764 R2=0.2955 MAE=0.8577 | MLP: RMSE=1.3995 R2=0.1532 MAE=0.9514 | NAIVE: RMSE=1.5211 R2=-0.0005 MAE=1.0695   (44.55s)\n",
            "[feature5][run 17/20] split: train=5,648 | test=1,412 | seed=513226\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 17] RF: RMSE=1.2640 R2=0.2511 MAE=0.8696 | DT: RMSE=1.4092 R2=0.0690 MAE=0.9792 | ADA: RMSE=1.3842 R2=0.1018 MAE=1.0275 | XGB: RMSE=1.2259 R2=0.2956 MAE=0.8213 | LGBM: RMSE=1.2182 R2=0.3044 MAE=0.8144 | MLP: RMSE=1.3613 R2=0.1314 MAE=0.9630 | NAIVE: RMSE=1.4608 R2=-0.0004 MAE=1.0485   (46.15s)\n",
            "[feature5][run 18/20] split: train=5,648 | test=1,412 | seed=128113\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 18] RF: RMSE=1.2852 R2=0.2436 MAE=0.8626 | DT: RMSE=1.4448 R2=0.0441 MAE=1.0145 | ADA: RMSE=1.4058 R2=0.0950 MAE=1.0227 | XGB: RMSE=1.2561 R2=0.2774 MAE=0.8291 | LGBM: RMSE=1.2546 R2=0.2792 MAE=0.8285 | MLP: RMSE=1.3357 R2=0.1829 MAE=0.9026 | NAIVE: RMSE=1.4780 R2=-0.0003 MAE=1.0362   (40.65s)\n",
            "[feature5][run 19/20] split: train=5,648 | test=1,412 | seed=839748\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 19] RF: RMSE=1.2708 R2=0.2436 MAE=0.8667 | DT: RMSE=1.4327 R2=0.0385 MAE=1.0193 | ADA: RMSE=1.3937 R2=0.0901 MAE=1.0379 | XGB: RMSE=1.2227 R2=0.2997 MAE=0.8108 | LGBM: RMSE=1.2335 R2=0.2873 MAE=0.8199 | MLP: RMSE=1.3257 R2=0.1767 MAE=0.8882 | NAIVE: RMSE=1.4612 R2=-0.0001 MAE=1.0483   (44.98s)\n",
            "[feature5][run 20/20] split: train=5,648 | test=1,412 | seed=450385\n",
            "[feature5] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature5.json\n",
            "[feature5] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature5] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature5] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature5] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature5] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature5] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature5][run 20] RF: RMSE=1.2947 R2=0.2620 MAE=0.8801 | DT: RMSE=1.4367 R2=0.0911 MAE=0.9858 | ADA: RMSE=1.4225 R2=0.1090 MAE=1.0480 | XGB: RMSE=1.2438 R2=0.3188 MAE=0.8272 | LGBM: RMSE=1.2390 R2=0.3240 MAE=0.8241 | MLP: RMSE=1.3258 R2=0.2261 MAE=0.8877 | NAIVE: RMSE=1.5070 R2=-0.0000 MAE=1.0677   (41.32s)\n",
            "[feature5] Resumo (média ± desvio) nas 20 runs:\n",
            "  NAIVE | RMSE=1.4778±0.0397 | R2=-0.0006±0.0006 | MAE=1.0576±0.0208\n",
            "  DT    | RMSE=1.4389±0.0418 | R2=0.0513±0.0227 | MAE=1.0098±0.0286\n",
            "  RF    | RMSE=1.2830±0.0418 | R2=0.2460±0.0171 | MAE=0.8764±0.0188\n",
            "  ADA   | RMSE=1.4040±0.0359 | R2=0.0968±0.0095 | MAE=1.0405±0.0176\n",
            "  XGB   | RMSE=1.2388±0.0439 | R2=0.2970±0.0198 | MAE=0.8228±0.0204\n",
            "  LGBM  | RMSE=1.2428±0.0456 | R2=0.2925±0.0234 | MAE=0.8266±0.0216\n",
            "  MLP   | RMSE=1.3486±0.0466 | R2=0.1665±0.0311 | MAE=0.9189±0.0236\n",
            "[feature5] Tempo total: 870.57s\n",
            "\n",
            "\n",
            "--- [feature6] Iniciando (5 variáveis, 7060 linhas após Z-score) ---\n",
            "[feature6] primeiras variáveis: TO_WI4804_01, TO_FY6104_01, TO_AI6401_01, TO_AI6402_01, TO_BO6311_EST1\n",
            "[feature6][run 01/20] split: train=5,648 | test=1,412 | seed=89250\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 01] RF: RMSE=1.4352 R2=0.0614 MAE=1.0289 | DT: RMSE=1.4413 R2=0.0534 MAE=1.0480 | ADA: RMSE=1.5085 R2=-0.0369 MAE=1.2093 | XGB: RMSE=1.5134 R2=-0.0436 MAE=1.0966 | LGBM: RMSE=1.4576 R2=0.0319 MAE=1.0437 | MLP: RMSE=1.4448 R2=0.0489 MAE=1.0311 | NAIVE: RMSE=1.4815 R2=-0.0001 MAE=1.0747   (13.44s)\n",
            "[feature6][run 02/20] split: train=5,648 | test=1,412 | seed=773956\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 02] RF: RMSE=1.3685 R2=0.0770 MAE=0.9949 | DT: RMSE=1.4011 R2=0.0325 MAE=1.0242 | ADA: RMSE=1.4596 R2=-0.0500 MAE=1.1856 | XGB: RMSE=1.4580 R2=-0.0476 MAE=1.0604 | LGBM: RMSE=1.4046 R2=0.0276 MAE=1.0230 | MLP: RMSE=1.4026 R2=0.0304 MAE=1.0543 | NAIVE: RMSE=1.4251 R2=-0.0009 MAE=1.0432   (15.29s)\n",
            "[feature6][run 03/20] split: train=5,648 | test=1,412 | seed=654571\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 03] RF: RMSE=1.4776 R2=0.0836 MAE=1.0313 | DT: RMSE=1.5063 R2=0.0477 MAE=1.0473 | ADA: RMSE=1.5442 R2=-0.0009 MAE=1.2185 | XGB: RMSE=1.5626 R2=-0.0249 MAE=1.1015 | LGBM: RMSE=1.5052 R2=0.0490 MAE=1.0470 | MLP: RMSE=1.5143 R2=0.0376 MAE=1.0594 | NAIVE: RMSE=1.5438 R2=-0.0004 MAE=1.0874   (16.73s)\n",
            "[feature6][run 04/20] split: train=5,648 | test=1,412 | seed=438878\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 04] RF: RMSE=1.4441 R2=0.0803 MAE=1.0150 | DT: RMSE=1.4716 R2=0.0450 MAE=1.0374 | ADA: RMSE=1.5119 R2=-0.0080 MAE=1.2038 | XGB: RMSE=1.5361 R2=-0.0405 MAE=1.0703 | LGBM: RMSE=1.4889 R2=0.0224 MAE=1.0451 | MLP: RMSE=1.4670 R2=0.0510 MAE=1.0060 | NAIVE: RMSE=1.5064 R2=-0.0007 MAE=1.0724   (15.51s)\n",
            "[feature6][run 05/20] split: train=5,648 | test=1,412 | seed=433015\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 05] RF: RMSE=1.4457 R2=0.0848 MAE=1.0061 | DT: RMSE=1.4892 R2=0.0289 MAE=1.0425 | ADA: RMSE=1.5121 R2=-0.0013 MAE=1.1844 | XGB: RMSE=1.5260 R2=-0.0197 MAE=1.0753 | LGBM: RMSE=1.4750 R2=0.0473 MAE=1.0256 | MLP: RMSE=1.4726 R2=0.0504 MAE=1.0145 | NAIVE: RMSE=1.5118 R2=-0.0008 MAE=1.0641   (14.20s)\n",
            "[feature6][run 06/20] split: train=5,648 | test=1,412 | seed=858597\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 06] RF: RMSE=1.3882 R2=0.0631 MAE=0.9982 | DT: RMSE=1.4105 R2=0.0327 MAE=1.0143 | ADA: RMSE=1.4810 R2=-0.0663 MAE=1.1911 | XGB: RMSE=1.4720 R2=-0.0535 MAE=1.0520 | LGBM: RMSE=1.4143 R2=0.0275 MAE=1.0120 | MLP: RMSE=1.3958 R2=0.0529 MAE=1.0011 | NAIVE: RMSE=1.4346 R2=-0.0005 MAE=1.0330   (15.74s)\n",
            "[feature6][run 07/20] split: train=5,648 | test=1,412 | seed=85945\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 07] RF: RMSE=1.3930 R2=0.0758 MAE=0.9871 | DT: RMSE=1.4303 R2=0.0256 MAE=1.0094 | ADA: RMSE=1.4702 R2=-0.0295 MAE=1.1637 | XGB: RMSE=1.4776 R2=-0.0398 MAE=1.0521 | LGBM: RMSE=1.4368 R2=0.0167 MAE=1.0146 | MLP: RMSE=1.4208 R2=0.0385 MAE=1.0334 | NAIVE: RMSE=1.4491 R2=-0.0001 MAE=1.0303   (14.44s)\n",
            "[feature6][run 08/20] split: train=5,648 | test=1,412 | seed=697368\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 08] RF: RMSE=1.3870 R2=0.0859 MAE=0.9991 | DT: RMSE=1.4246 R2=0.0357 MAE=1.0203 | ADA: RMSE=1.4815 R2=-0.0429 MAE=1.1930 | XGB: RMSE=1.4917 R2=-0.0572 MAE=1.0839 | LGBM: RMSE=1.4449 R2=0.0080 MAE=1.0390 | MLP: RMSE=1.4066 R2=0.0599 MAE=1.0265 | NAIVE: RMSE=1.4520 R2=-0.0017 MAE=1.0492   (15.32s)\n",
            "[feature6][run 09/20] split: train=5,648 | test=1,412 | seed=201469\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 09] RF: RMSE=1.4000 R2=0.0558 MAE=1.0136 | DT: RMSE=1.4302 R2=0.0147 MAE=1.0427 | ADA: RMSE=1.4805 R2=-0.0560 MAE=1.2012 | XGB: RMSE=1.5070 R2=-0.0941 MAE=1.0903 | LGBM: RMSE=1.4504 R2=-0.0133 MAE=1.0409 | MLP: RMSE=1.4108 R2=0.0412 MAE=1.0202 | NAIVE: RMSE=1.4414 R2=-0.0008 MAE=1.0538   (14.76s)\n",
            "[feature6][run 10/20] split: train=5,648 | test=1,412 | seed=94177\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 10] RF: RMSE=1.3464 R2=0.0532 MAE=0.9765 | DT: RMSE=1.3773 R2=0.0092 MAE=1.0076 | ADA: RMSE=1.4407 R2=-0.0842 MAE=1.1652 | XGB: RMSE=1.4375 R2=-0.0793 MAE=1.0266 | LGBM: RMSE=1.3881 R2=-0.0063 MAE=1.0070 | MLP: RMSE=1.3582 R2=0.0366 MAE=0.9785 | NAIVE: RMSE=1.3853 R2=-0.0023 MAE=1.0158   (14.33s)\n",
            "[feature6][run 11/20] split: train=5,648 | test=1,412 | seed=526478\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 11] RF: RMSE=1.4668 R2=0.0465 MAE=1.0265 | DT: RMSE=1.4894 R2=0.0170 MAE=1.0578 | ADA: RMSE=1.5192 R2=-0.0228 MAE=1.2001 | XGB: RMSE=1.5403 R2=-0.0514 MAE=1.0794 | LGBM: RMSE=1.5102 R2=-0.0107 MAE=1.0526 | MLP: RMSE=1.4798 R2=0.0296 MAE=1.0259 | NAIVE: RMSE=1.5024 R2=-0.0002 MAE=1.0673   (16.13s)\n",
            "[feature6][run 12/20] split: train=5,648 | test=1,412 | seed=975622\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 12] RF: RMSE=1.3887 R2=0.1084 MAE=0.9880 | DT: RMSE=1.4488 R2=0.0296 MAE=1.0357 | ADA: RMSE=1.4921 R2=-0.0293 MAE=1.1918 | XGB: RMSE=1.4770 R2=-0.0086 MAE=1.0539 | LGBM: RMSE=1.4285 R2=0.0565 MAE=1.0175 | MLP: RMSE=1.4179 R2=0.0704 MAE=1.0273 | NAIVE: RMSE=1.4717 R2=-0.0014 MAE=1.0512   (13.49s)\n",
            "[feature6][run 13/20] split: train=5,648 | test=1,412 | seed=735752\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 13] RF: RMSE=1.4495 R2=0.0744 MAE=1.0199 | DT: RMSE=1.4827 R2=0.0315 MAE=1.0507 | ADA: RMSE=1.5108 R2=-0.0055 MAE=1.1957 | XGB: RMSE=1.5356 R2=-0.0388 MAE=1.0726 | LGBM: RMSE=1.4843 R2=0.0294 MAE=1.0398 | MLP: RMSE=1.4666 R2=0.0524 MAE=1.0412 | NAIVE: RMSE=1.5067 R2=-0.0000 MAE=1.0687   (14.93s)\n",
            "[feature6][run 14/20] split: train=5,648 | test=1,412 | seed=761139\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 14] RF: RMSE=1.4147 R2=0.0776 MAE=1.0129 | DT: RMSE=1.4452 R2=0.0375 MAE=1.0333 | ADA: RMSE=1.4938 R2=-0.0284 MAE=1.1927 | XGB: RMSE=1.4888 R2=-0.0215 MAE=1.0707 | LGBM: RMSE=1.4506 R2=0.0302 MAE=1.0385 | MLP: RMSE=1.4309 R2=0.0564 MAE=1.0337 | NAIVE: RMSE=1.4732 R2=-0.0002 MAE=1.0623   (16.76s)\n",
            "[feature6][run 15/20] split: train=5,648 | test=1,412 | seed=717477\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 15] RF: RMSE=1.5046 R2=0.0504 MAE=1.0742 | DT: RMSE=1.5361 R2=0.0102 MAE=1.0988 | ADA: RMSE=1.5710 R2=-0.0353 MAE=1.2490 | XGB: RMSE=1.5809 R2=-0.0484 MAE=1.1180 | LGBM: RMSE=1.5428 R2=0.0015 MAE=1.0959 | MLP: RMSE=1.5299 R2=0.0181 MAE=1.0724 | NAIVE: RMSE=1.5440 R2=-0.0001 MAE=1.1093   (14.92s)\n",
            "[feature6][run 16/20] split: train=5,648 | test=1,412 | seed=786064\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 16] RF: RMSE=1.4698 R2=0.0660 MAE=1.0378 | DT: RMSE=1.5034 R2=0.0227 MAE=1.0656 | ADA: RMSE=1.5352 R2=-0.0190 MAE=1.2166 | XGB: RMSE=1.5533 R2=-0.0433 MAE=1.1125 | LGBM: RMSE=1.5155 R2=0.0070 MAE=1.0803 | MLP: RMSE=1.4936 R2=0.0355 MAE=1.0468 | NAIVE: RMSE=1.5211 R2=-0.0005 MAE=1.0695   (14.07s)\n",
            "[feature6][run 17/20] split: train=5,648 | test=1,412 | seed=513226\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 17] RF: RMSE=1.4313 R2=0.0397 MAE=1.0103 | DT: RMSE=1.4460 R2=0.0198 MAE=1.0308 | ADA: RMSE=1.4912 R2=-0.0424 MAE=1.1871 | XGB: RMSE=1.5189 R2=-0.0815 MAE=1.0714 | LGBM: RMSE=1.4696 R2=-0.0124 MAE=1.0369 | MLP: RMSE=1.4311 R2=0.0399 MAE=0.9948 | NAIVE: RMSE=1.4608 R2=-0.0004 MAE=1.0485   (14.27s)\n",
            "[feature6][run 18/20] split: train=5,648 | test=1,412 | seed=128113\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 18] RF: RMSE=1.4059 R2=0.0949 MAE=0.9880 | DT: RMSE=1.4494 R2=0.0379 MAE=1.0245 | ADA: RMSE=1.4910 R2=-0.0180 MAE=1.1736 | XGB: RMSE=1.4851 R2=-0.0100 MAE=1.0455 | LGBM: RMSE=1.4306 R2=0.0627 MAE=0.9963 | MLP: RMSE=1.4439 R2=0.0452 MAE=0.9929 | NAIVE: RMSE=1.4780 R2=-0.0003 MAE=1.0362   (13.90s)\n",
            "[feature6][run 19/20] split: train=5,648 | test=1,412 | seed=839748\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 19] RF: RMSE=1.4066 R2=0.0732 MAE=0.9974 | DT: RMSE=1.4458 R2=0.0209 MAE=1.0377 | ADA: RMSE=1.4837 R2=-0.0312 MAE=1.1882 | XGB: RMSE=1.4728 R2=-0.0160 MAE=1.0531 | LGBM: RMSE=1.4282 R2=0.0445 MAE=1.0156 | MLP: RMSE=1.4337 R2=0.0372 MAE=1.0466 | NAIVE: RMSE=1.4612 R2=-0.0001 MAE=1.0483   (16.12s)\n",
            "[feature6][run 20/20] split: train=5,648 | test=1,412 | seed=450385\n",
            "[feature6] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature6.json\n",
            "[feature6] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature6] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature6] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature6] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature6] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature6] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature6][run 20] RF: RMSE=1.4639 R2=0.0564 MAE=1.0311 | DT: RMSE=1.4941 R2=0.0171 MAE=1.0602 | ADA: RMSE=1.5305 R2=-0.0314 MAE=1.2082 | XGB: RMSE=1.5379 R2=-0.0414 MAE=1.0862 | LGBM: RMSE=1.4973 R2=0.0128 MAE=1.0572 | MLP: RMSE=1.4738 R2=0.0436 MAE=1.0487 | NAIVE: RMSE=1.5070 R2=-0.0000 MAE=1.0677   (14.34s)\n",
            "[feature6] Resumo (média ± desvio) nas 20 runs:\n",
            "  NAIVE | RMSE=1.4778±0.0397 | R2=-0.0006±0.0006 | MAE=1.0576±0.0208\n",
            "  DT    | RMSE=1.4562±0.0387 | R2=0.0285±0.0120 | MAE=1.0394±0.0209\n",
            "  RF    | RMSE=1.4244±0.0399 | R2=0.0704±0.0169 | MAE=1.0118±0.0221\n",
            "  ADA   | RMSE=1.5004±0.0297 | R2=-0.0320±0.0209 | MAE=1.1959±0.0189\n",
            "  XGB   | RMSE=1.5086±0.0370 | R2=-0.0431±0.0226 | MAE=1.0736±0.0227\n",
            "  LGBM  | RMSE=1.4612±0.0398 | R2=0.0216±0.0227 | MAE=1.0364±0.0235\n",
            "  MLP   | RMSE=1.4447±0.0415 | R2=0.0438±0.0116 | MAE=1.0278±0.0237\n",
            "[feature6] Tempo total: 298.69s\n",
            "\n",
            "\n",
            "--- [feature7] Iniciando (10 variáveis, 7060 linhas após Z-score) ---\n",
            "[feature7] primeiras variáveis: TO_SIMF6432, TO_SIMF6431, TO_PHY4804_02, TO_SIMF641201, TO_SIMF6421...\n",
            "[feature7][run 01/20] split: train=5,648 | test=1,412 | seed=89250\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 01] RF: RMSE=1.3162 R2=0.2106 MAE=0.9010 | DT: RMSE=1.4388 R2=0.0567 MAE=1.0113 | ADA: RMSE=1.4584 R2=0.0309 MAE=1.1438 | XGB: RMSE=1.3055 R2=0.2234 MAE=0.8838 | LGBM: RMSE=1.3177 R2=0.2088 MAE=0.8972 | MLP: RMSE=1.3867 R2=0.1238 MAE=0.9768 | NAIVE: RMSE=1.4815 R2=-0.0001 MAE=1.0747   (23.80s)\n",
            "[feature7][run 02/20] split: train=5,648 | test=1,412 | seed=773956\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 02] RF: RMSE=1.2783 R2=0.1947 MAE=0.8792 | DT: RMSE=1.3850 R2=0.0547 MAE=0.9877 | ADA: RMSE=1.4208 R2=0.0051 MAE=1.1294 | XGB: RMSE=1.2546 R2=0.2243 MAE=0.8517 | LGBM: RMSE=1.2637 R2=0.2130 MAE=0.8658 | MLP: RMSE=1.3269 R2=0.1323 MAE=0.9134 | NAIVE: RMSE=1.4251 R2=-0.0009 MAE=1.0432   (24.42s)\n",
            "[feature7][run 03/20] split: train=5,648 | test=1,412 | seed=654571\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 03] RF: RMSE=1.3778 R2=0.2032 MAE=0.9144 | DT: RMSE=1.4997 R2=0.0560 MAE=1.0307 | ADA: RMSE=1.4883 R2=0.0703 MAE=1.1429 | XGB: RMSE=1.3833 R2=0.1968 MAE=0.8943 | LGBM: RMSE=1.3938 R2=0.1846 MAE=0.9137 | MLP: RMSE=1.4828 R2=0.0771 MAE=0.9851 | NAIVE: RMSE=1.5438 R2=-0.0004 MAE=1.0874   (24.62s)\n",
            "[feature7][run 04/20] split: train=5,648 | test=1,412 | seed=438878\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 04] RF: RMSE=1.3051 R2=0.2488 MAE=0.8830 | DT: RMSE=1.4330 R2=0.0944 MAE=1.0142 | ADA: RMSE=1.4552 R2=0.0662 MAE=1.1225 | XGB: RMSE=1.3083 R2=0.2452 MAE=0.8773 | LGBM: RMSE=1.3154 R2=0.2369 MAE=0.8811 | MLP: RMSE=1.3990 R2=0.1370 MAE=0.9719 | NAIVE: RMSE=1.5064 R2=-0.0007 MAE=1.0724   (23.57s)\n",
            "[feature7][run 05/20] split: train=5,648 | test=1,412 | seed=433015\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 05] RF: RMSE=1.3537 R2=0.1976 MAE=0.9037 | DT: RMSE=1.4917 R2=0.0257 MAE=1.0394 | ADA: RMSE=1.4724 R2=0.0507 MAE=1.1179 | XGB: RMSE=1.3481 R2=0.2042 MAE=0.8899 | LGBM: RMSE=1.3547 R2=0.1964 MAE=0.8955 | MLP: RMSE=1.4215 R2=0.1152 MAE=0.9744 | NAIVE: RMSE=1.5118 R2=-0.0008 MAE=1.0641   (24.13s)\n",
            "[feature7][run 06/20] split: train=5,648 | test=1,412 | seed=858597\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 06] RF: RMSE=1.2598 R2=0.2285 MAE=0.8815 | DT: RMSE=1.3980 R2=0.0499 MAE=0.9879 | ADA: RMSE=1.4264 R2=0.0109 MAE=1.1295 | XGB: RMSE=1.2753 R2=0.2093 MAE=0.8796 | LGBM: RMSE=1.2754 R2=0.2092 MAE=0.8812 | MLP: RMSE=1.3553 R2=0.1071 MAE=0.9749 | NAIVE: RMSE=1.4346 R2=-0.0005 MAE=1.0330   (25.20s)\n",
            "[feature7][run 07/20] split: train=5,648 | test=1,412 | seed=85945\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 07] RF: RMSE=1.2647 R2=0.2382 MAE=0.8751 | DT: RMSE=1.4128 R2=0.0494 MAE=0.9920 | ADA: RMSE=1.4256 R2=0.0320 MAE=1.1187 | XGB: RMSE=1.2586 R2=0.2456 MAE=0.8697 | LGBM: RMSE=1.2819 R2=0.2173 MAE=0.8843 | MLP: RMSE=1.3385 R2=0.1467 MAE=0.9374 | NAIVE: RMSE=1.4491 R2=-0.0001 MAE=1.0303   (24.18s)\n",
            "[feature7][run 08/20] split: train=5,648 | test=1,412 | seed=697368\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 08] RF: RMSE=1.2774 R2=0.2247 MAE=0.8754 | DT: RMSE=1.4133 R2=0.0509 MAE=0.9947 | ADA: RMSE=1.4219 R2=0.0394 MAE=1.1303 | XGB: RMSE=1.2934 R2=0.2051 MAE=0.8711 | LGBM: RMSE=1.2989 R2=0.1983 MAE=0.8786 | MLP: RMSE=1.3262 R2=0.1643 MAE=0.9211 | NAIVE: RMSE=1.4520 R2=-0.0017 MAE=1.0492   (24.22s)\n",
            "[feature7][run 09/20] split: train=5,648 | test=1,412 | seed=201469\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 09] RF: RMSE=1.2839 R2=0.2059 MAE=0.8880 | DT: RMSE=1.3936 R2=0.0645 MAE=0.9964 | ADA: RMSE=1.4368 R2=0.0056 MAE=1.1498 | XGB: RMSE=1.3097 R2=0.1737 MAE=0.8854 | LGBM: RMSE=1.3089 R2=0.1747 MAE=0.8957 | MLP: RMSE=1.3616 R2=0.1069 MAE=0.9980 | NAIVE: RMSE=1.4414 R2=-0.0008 MAE=1.0538   (24.15s)\n",
            "[feature7][run 10/20] split: train=5,648 | test=1,412 | seed=94177\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 10] RF: RMSE=1.2422 R2=0.1941 MAE=0.8702 | DT: RMSE=1.3657 R2=0.0259 MAE=0.9819 | ADA: RMSE=1.4191 R2=-0.0518 MAE=1.1263 | XGB: RMSE=1.2324 R2=0.2067 MAE=0.8473 | LGBM: RMSE=1.2403 R2=0.1965 MAE=0.8599 | MLP: RMSE=1.3227 R2=0.0863 MAE=0.9385 | NAIVE: RMSE=1.3853 R2=-0.0023 MAE=1.0158   (24.34s)\n",
            "[feature7][run 11/20] split: train=5,648 | test=1,412 | seed=526478\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 11] RF: RMSE=1.3493 R2=0.1932 MAE=0.9165 | DT: RMSE=1.4814 R2=0.0275 MAE=1.0360 | ADA: RMSE=1.4777 R2=0.0323 MAE=1.1448 | XGB: RMSE=1.3457 R2=0.1974 MAE=0.9011 | LGBM: RMSE=1.3378 R2=0.2069 MAE=0.8989 | MLP: RMSE=1.4129 R2=0.1153 MAE=0.9890 | NAIVE: RMSE=1.5024 R2=-0.0002 MAE=1.0673   (23.21s)\n",
            "[feature7][run 12/20] split: train=5,648 | test=1,412 | seed=975622\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 12] RF: RMSE=1.2846 R2=0.2371 MAE=0.8786 | DT: RMSE=1.4182 R2=0.0701 MAE=0.9903 | ADA: RMSE=1.4421 R2=0.0385 MAE=1.1314 | XGB: RMSE=1.2933 R2=0.2267 MAE=0.8806 | LGBM: RMSE=1.2948 R2=0.2249 MAE=0.8827 | MLP: RMSE=1.3558 R2=0.1502 MAE=0.9255 | NAIVE: RMSE=1.4717 R2=-0.0014 MAE=1.0512   (24.73s)\n",
            "[feature7][run 13/20] split: train=5,648 | test=1,412 | seed=735752\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 13] RF: RMSE=1.3501 R2=0.1970 MAE=0.8977 | DT: RMSE=1.4734 R2=0.0436 MAE=1.0291 | ADA: RMSE=1.4655 R2=0.0538 MAE=1.1193 | XGB: RMSE=1.3506 R2=0.1965 MAE=0.8902 | LGBM: RMSE=1.3641 R2=0.1803 MAE=0.9020 | MLP: RMSE=1.4051 R2=0.1303 MAE=0.9359 | NAIVE: RMSE=1.5067 R2=-0.0000 MAE=1.0687   (24.05s)\n",
            "[feature7][run 14/20] split: train=5,648 | test=1,412 | seed=761139\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 14] RF: RMSE=1.3196 R2=0.1975 MAE=0.8884 | DT: RMSE=1.4539 R2=0.0258 MAE=1.0242 | ADA: RMSE=1.4303 R2=0.0571 MAE=1.1017 | XGB: RMSE=1.3330 R2=0.1811 MAE=0.8783 | LGBM: RMSE=1.3343 R2=0.1795 MAE=0.8924 | MLP: RMSE=1.3789 R2=0.1237 MAE=0.9408 | NAIVE: RMSE=1.4732 R2=-0.0002 MAE=1.0623   (24.78s)\n",
            "[feature7][run 15/20] split: train=5,648 | test=1,412 | seed=717477\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 15] RF: RMSE=1.3421 R2=0.2444 MAE=0.9210 | DT: RMSE=1.4971 R2=0.0598 MAE=1.0573 | ADA: RMSE=1.5115 R2=0.0416 MAE=1.1941 | XGB: RMSE=1.3564 R2=0.2282 MAE=0.9160 | LGBM: RMSE=1.3649 R2=0.2185 MAE=0.9264 | MLP: RMSE=1.4237 R2=0.1497 MAE=0.9966 | NAIVE: RMSE=1.5440 R2=-0.0001 MAE=1.1093   (24.68s)\n",
            "[feature7][run 16/20] split: train=5,648 | test=1,412 | seed=786064\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 16] RF: RMSE=1.3397 R2=0.2240 MAE=0.9037 | DT: RMSE=1.4859 R2=0.0453 MAE=1.0379 | ADA: RMSE=1.4733 R2=0.0615 MAE=1.1406 | XGB: RMSE=1.3071 R2=0.2612 MAE=0.8777 | LGBM: RMSE=1.3216 R2=0.2448 MAE=0.8911 | MLP: RMSE=1.4290 R2=0.1171 MAE=0.9556 | NAIVE: RMSE=1.5211 R2=-0.0005 MAE=1.0695   (25.50s)\n",
            "[feature7][run 17/20] split: train=5,648 | test=1,412 | seed=513226\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 17] RF: RMSE=1.2868 R2=0.2238 MAE=0.8781 | DT: RMSE=1.4260 R2=0.0468 MAE=1.0039 | ADA: RMSE=1.4277 R2=0.0445 MAE=1.1136 | XGB: RMSE=1.2896 R2=0.2204 MAE=0.8673 | LGBM: RMSE=1.2919 R2=0.2176 MAE=0.8789 | MLP: RMSE=1.3914 R2=0.0924 MAE=0.9726 | NAIVE: RMSE=1.4608 R2=-0.0004 MAE=1.0485   (25.05s)\n",
            "[feature7][run 18/20] split: train=5,648 | test=1,412 | seed=128113\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 18] RF: RMSE=1.3064 R2=0.2184 MAE=0.8773 | DT: RMSE=1.4479 R2=0.0399 MAE=1.0079 | ADA: RMSE=1.4355 R2=0.0563 MAE=1.1139 | XGB: RMSE=1.3053 R2=0.2198 MAE=0.8748 | LGBM: RMSE=1.3207 R2=0.2012 MAE=0.8892 | MLP: RMSE=1.3683 R2=0.1426 MAE=0.9547 | NAIVE: RMSE=1.4780 R2=-0.0003 MAE=1.0362   (24.08s)\n",
            "[feature7][run 19/20] split: train=5,648 | test=1,412 | seed=839748\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 19] RF: RMSE=1.2793 R2=0.2334 MAE=0.8782 | DT: RMSE=1.4172 R2=0.0592 MAE=0.9986 | ADA: RMSE=1.4398 R2=0.0290 MAE=1.1386 | XGB: RMSE=1.2795 R2=0.2331 MAE=0.8674 | LGBM: RMSE=1.2944 R2=0.2152 MAE=0.8847 | MLP: RMSE=1.3736 R2=0.1162 MAE=0.9467 | NAIVE: RMSE=1.4612 R2=-0.0001 MAE=1.0483   (23.91s)\n",
            "[feature7][run 20/20] split: train=5,648 | test=1,412 | seed=450385\n",
            "[feature7] Hiperparâmetros carregados de JSON: melhores_hiperparametros_feature7.json\n",
            "[feature7] Aplicados hiperparâmetros em RF: ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'bootstrap']\n",
            "[feature7] Aplicados hiperparâmetros em DT: ['max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'criterion', 'splitter']\n",
            "[feature7] Aplicados hiperparâmetros em ADA: ['n_estimators', 'learning_rate', 'loss', 'estimator__max_depth', 'estimator__min_samples_leaf']\n",
            "[feature7] Aplicados hiperparâmetros em XGB: ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'colsample_bytree', 'min_child_weight', 'reg_lambda', 'reg_alpha', 'gamma', 'tree_method', 'eval_metric']\n",
            "[feature7] Aplicados hiperparâmetros em LGBM: ['n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'subsample', 'colsample_bytree', 'reg_lambda', 'reg_alpha']\n",
            "[feature7] Aplicados hiperparâmetros em MLP: ['hidden_layer_sizes', 'activation', 'alpha', 'learning_rate_init', 'learning_rate', 'early_stopping', 'max_iter', 'validation_fraction', 'n_iter_no_change']\n",
            "[feature7][run 20] RF: RMSE=1.3109 R2=0.2433 MAE=0.8927 | DT: RMSE=1.4554 R2=0.0673 MAE=1.0043 | ADA: RMSE=1.4869 R2=0.0265 MAE=1.1453 | XGB: RMSE=1.2973 R2=0.2589 MAE=0.8738 | LGBM: RMSE=1.3156 R2=0.2378 MAE=0.8966 | MLP: RMSE=1.3867 R2=0.1533 MAE=0.9501 | NAIVE: RMSE=1.5070 R2=-0.0000 MAE=1.0677   (24.78s)\n",
            "[feature7] Resumo (média ± desvio) nas 20 runs:\n",
            "  NAIVE | RMSE=1.4778±0.0397 | R2=-0.0006±0.0006 | MAE=1.0576±0.0208\n",
            "  DT    | RMSE=1.4394±0.0388 | R2=0.0507±0.0167 | MAE=1.0113±0.0208\n",
            "  RF    | RMSE=1.3064±0.0357 | R2=0.2179±0.0186 | MAE=0.8902±0.0149\n",
            "  ADA   | RMSE=1.4508±0.0264 | R2=0.0350±0.0271 | MAE=1.1327±0.0189\n",
            "  XGB   | RMSE=1.3064±0.0369 | R2=0.2179±0.0232 | MAE=0.8789±0.0152\n",
            "  LGBM  | RMSE=1.3146±0.0362 | R2=0.2081±0.0192 | MAE=0.8898±0.0146\n",
            "  MLP   | RMSE=1.3823±0.0395 | R2=0.1244±0.0228 | MAE=0.9580±0.0248\n",
            "[feature7] Tempo total: 487.41s\n",
            "\n",
            "================================================================================\n",
            "Arquivo salvo: outputs/Model_Results_B_20_features.xlsx\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ====== Config simples de log ======\n",
        "VERBOSE = True\n",
        "PRINT_EVERY = 1\n",
        "N_RUNS = 20\n",
        "SEED_BASE = 42\n",
        "\n",
        "# ====== Helpers: carregar e aplicar hiperparâmetros (CSV -> JSON fallback) ======\n",
        "def _coerce(val):\n",
        "    \"\"\"Converte string do CSV em tipos Python (int/float/bool/list/tuple/dict) quando possível.\"\"\"\n",
        "    if pd.isna(val):\n",
        "        return None\n",
        "    if isinstance(val, (int, float, bool)):\n",
        "        return val\n",
        "    s = str(val).strip()\n",
        "    try:\n",
        "        return ast.literal_eval(s)\n",
        "    except Exception:\n",
        "        return s\n",
        "\n",
        "def carregar_hiperparams(tag: str) -> dict:\n",
        "    \"\"\"\n",
        "    Procura hiperparâmetros para um feature set `tag` em:\n",
        "      1) melhores_hiperparametros_{tag}.csv\n",
        "      2) melhores_hiperparametros_{tag}.json\n",
        "      3) equivalentes com 'features' (ex.: feature1 -> features1)\n",
        "      4) as mesmas variações em /mnt/data\n",
        "\n",
        "    CSV suportado em dois formatos:\n",
        "      - Longo: colunas ['model','param','value']\n",
        "      - Largo: col 'model' + colunas = nomes de parâmetros\n",
        "\n",
        "    Retorna dict: { \"RF\": {...}, \"DT\": {...}, \"XGB\": {...}, \"LGBM\": {...}, \"MLP\": {...}, ... }\n",
        "    \"\"\"\n",
        "    def _paths(base):\n",
        "        yield f\"{base}.csv\"\n",
        "        yield f\"{os.path.basename(base)}.csv\"\n",
        "        yield f\"{base}.json\"\n",
        "        yield f\"{os.path.basename(base)}.json\"\n",
        "\n",
        "    alt_tag = tag.replace(\"feature\", \"features\")\n",
        "    bases = [f\"melhores_hiperparametros_{tag}\", f\"melhores_hiperparametros_{alt_tag}\"]\n",
        "\n",
        "    # tenta CSV primeiro\n",
        "    for base in bases:\n",
        "        for path in _paths(base):\n",
        "            if os.path.exists(path) and path.lower().endswith(\".csv\"):\n",
        "                try:\n",
        "                    dfp = pd.read_csv(path)\n",
        "                    cols_lower = {c.lower() for c in dfp.columns}\n",
        "                    out = {}\n",
        "                    # formato longo\n",
        "                    if {\"model\", \"param\", \"value\"}.issubset(cols_lower):\n",
        "                        mcol = next(c for c in dfp.columns if c.lower() == \"model\")\n",
        "                        pcol = next(c for c in dfp.columns if c.lower() == \"param\")\n",
        "                        vcol = next(c for c in dfp.columns if c.lower() == \"value\")\n",
        "                        for mdl, subdf in dfp.groupby(mcol):\n",
        "                            d = {}\n",
        "                            for _, row in subdf.iterrows():\n",
        "                                d[str(row[pcol]).strip()] = _coerce(row[vcol])\n",
        "                            out[str(mdl).strip()] = d\n",
        "                        if VERBOSE: print(f\"[{tag}] Hiperparâmetros carregados de CSV (longo): {path}\")\n",
        "                        return out\n",
        "                    # formato largo\n",
        "                    if \"model\" in cols_lower:\n",
        "                        mcol = next(c for c in dfp.columns if c.lower() == \"model\")\n",
        "                        for _, row in dfp.iterrows():\n",
        "                            mdl = str(row[mcol]).strip()\n",
        "                            d = {c: _coerce(row[c]) for c in dfp.columns if c != mcol and not pd.isna(row[c])}\n",
        "                            if d:\n",
        "                                out[mdl] = d\n",
        "                        if VERBOSE: print(f\"[{tag}] Hiperparâmetros carregados de CSV (largo): {path}\")\n",
        "                        return out\n",
        "\n",
        "                    if VERBOSE: print(f\"[{tag}] CSV encontrado mas formato não reconhecido: {path}\")\n",
        "                except Exception as e:\n",
        "                    if VERBOSE: print(f\"[{tag}] Falha lendo CSV {path}: {e}\")\n",
        "\n",
        "    # fallback: JSON\n",
        "    for base in bases:\n",
        "        for path in _paths(base):\n",
        "            if os.path.exists(path) and path.lower().endswith(\".json\"):\n",
        "                try:\n",
        "                    with open(path, \"r\") as f:\n",
        "                        data = json.load(f)\n",
        "                    if VERBOSE: print(f\"[{tag}] Hiperparâmetros carregados de JSON: {path}\")\n",
        "                    return data\n",
        "                except Exception as e:\n",
        "                    if VERBOSE: print(f\"[{tag}] Falha lendo JSON {path}: {e}\")\n",
        "\n",
        "    if VERBOSE: print(f\"[{tag}] Nenhum arquivo de hiperparâmetros encontrado.\")\n",
        "    return {}\n",
        "\n",
        "def _alias_keys(best: dict, key: str, aliases: list):\n",
        "    \"\"\"Tenta best[key] e variações de nome de modelo (aliases).\"\"\"\n",
        "    for k in [key] + aliases:\n",
        "        if k in best:\n",
        "            return best[k]\n",
        "    return None\n",
        "\n",
        "def aplicar_hiperparams(tag: str, modelos: dict):\n",
        "    \"\"\"\n",
        "    Aplica hiperparâmetros do arquivo correspondente ao feature set `tag`.\n",
        "    Para o MLP (Pipeline com passo 'model'), prefixa 'model__' automaticamente se faltar.\n",
        "    \"\"\"\n",
        "    best = carregar_hiperparams(tag)\n",
        "    if not best:\n",
        "        return\n",
        "\n",
        "    mapa = {\n",
        "        \"RF\":   [\"RandomForestRegressor\", \"RandomForest\", \"rf\"],\n",
        "        \"DT\":   [\"DecisionTreeRegressor\", \"DecisionTree\", \"dt\"],\n",
        "        \"XGB\":  [\"XGBRegressor\", \"xgb\", \"xgboost\"],\n",
        "        \"LGBM\": [\"LGBMRegressor\", \"LightGBM\", \"lgbm\", \"lgb\"],\n",
        "        \"MLP\":  [\"MLPRegressor\", \"NeuralNetwork\", \"NN\", \"mlp\"],\n",
        "        \"GB\":   [\"GradientBoostingRegressor\", \"GB\", \"gbr\"],\n",
        "        \"ADA\":  [\"AdaBoostRegressor\", \"ADA\", \"abr\"],\n",
        "    }\n",
        "\n",
        "    for nome_modelo, est in modelos.items():\n",
        "        params = _alias_keys(best, nome_modelo, mapa.get(nome_modelo, []))\n",
        "        if not params:\n",
        "            continue\n",
        "        try:\n",
        "            if nome_modelo == \"MLP\":\n",
        "                # se vier sem prefixo, aplica 'model__'\n",
        "                pref = {}\n",
        "                for k, v in params.items():\n",
        "                    kk = k if \"__\" in k else f\"model__{k}\"\n",
        "                    pref[kk] = v\n",
        "                est.set_params(**pref)\n",
        "            else:\n",
        "                est.set_params(**params)\n",
        "\n",
        "            if VERBOSE:\n",
        "                print(f\"[{tag}] Aplicados hiperparâmetros em {nome_modelo}: {list(params.keys())}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"[{tag}] Aviso: não apliquei hiperparâmetros em {nome_modelo}: {e}\")\n",
        "\n",
        "# ====== Dados ======\n",
        "df = pd.read_csv('dados_2h_aggregado_final.csv')\n",
        "df['Data'] = pd.to_datetime(df['Data'])\n",
        "\n",
        "features1 = ['TO_AI6401_01', 'TO_AI6402_01', 'TO_BO6311_EST1', 'TO_DI6311_01', 'TO_FI6311_01',\n",
        "             'TO_FI8271_01', 'TO_FY6104_01', 'TO_LI6401_01', 'TO_LI6401_02', 'TO_LI6402_01',\n",
        "             'TO_LI6411_01', 'TO_LI6411_02', 'TO_LI6412_01', 'TO_LI6412_02', 'TO_LI6431_01',\n",
        "             'TO_LI6432_01', 'TO_MF6401_M1_EST1', 'TO_MF6402_M1_EST1', 'TO_MF6411_M1_EST1',\n",
        "             'TO_MF6412_M1_EST1', 'TO_MF6421_M1_EST1', 'TO_PHY4804_02', 'TO_PHY4814_02', 'TO_SIMF640101',\n",
        "             'TO_SIMF640102', 'TO_SIMF640201', 'TO_SIMF640202', 'TO_SIMF641101', 'TO_SIMF641102',\n",
        "             'TO_SIMF641201', 'TO_SIMF641202', 'TO_SIMF6421', 'TO_SIMF6422', 'TO_SIMF6431', 'TO_SIMF6432', 'TO_WI4804_01']\n",
        "features2 = ['TO_WI4804_01', 'TO_PHY4814_02', 'TO_PHY4804_02', 'TO_SIMF641201', 'TO_LI6412_01', 'TO_SIMF640202', 'TO_MF6401_M1_EST1', 'TO_SIMF6422', 'TO_SIMF641102', 'TO_FI8271_01']\n",
        "features3 = ['TO_MF6412_M1_EST1', 'TO_FI8271_01', 'TO_PHY4814_02', 'TO_WI4804_01', 'TO_SIMF6421', 'TO_FI6311_01', 'TO_PHY4804_02', 'TO_SIMF6431', 'TO_SIMF640202', 'TO_LI6411_01']\n",
        "features4 = ['TO_PHY4804_02', 'TO_AI6401_01', 'TO_AI6402_01', 'TO_LI6412_01', 'TO_LI6412_02',\n",
        "             'TO_LI6431_01', 'TO_FI8271_01', 'TO_PHY4814_02', 'TO_FY6104_01', 'TO_WI4804_01',\n",
        "             'TO_SIMF640101', 'TO_SIMF640201', 'TO_SIMF640202', 'TO_SIMF641101', 'TO_SIMF641102',\n",
        "             'TO_SIMF641201', 'TO_SIMF641202', 'TO_SIMF6421', 'TO_SIMF6422', 'TO_SIMF6431']\n",
        "groups = [\n",
        "    \"TO_WI4804_01\", \"TO_FY6104_01\", \"TO_AI6401_01\", \"TO_AI6402_01\", \"TO_BO6311_EST1\"\n",
        "]\n",
        "\n",
        "mim = [\n",
        "    \"TO_SIMF6432\", \"TO_SIMF6431\", \"TO_PHY4804_02\", \"TO_SIMF641201\", \"TO_SIMF6421\",\n",
        "    \"TO_SIMF640101\", \"TO_PHY4814_02\", \"TO_SIMF6422\", \"TO_WI4804_01\", \"TO_SIMF640202\"\n",
        "]\n",
        "\n",
        "FEATURE_SETS = {\n",
        "    \"feature1\": features1,\n",
        "    \"feature2\": features2,\n",
        "    \"feature3\": features3,\n",
        "    \"feature4\": features4,\n",
        "    # \"feature5\": Backward,\n",
        "    # \"feature6\": groups,\n",
        "    # \"feature7\": mim,\n",
        "}\n",
        "y_full = df['P_CONFLTTO_QQ_GLOBAL_SIO2'].values\n",
        "\n",
        "# ====== Z-score (remover outliers) ======\n",
        "USE_ZSCORE   = True\n",
        "ZS_THRESH    = 3.0\n",
        "\n",
        "if USE_ZSCORE:\n",
        "    z = (y_full - y_full.mean()) / (y_full.std() if y_full.std() > 0 else 1.0)\n",
        "    mask = np.abs(z) <= ZS_THRESH\n",
        "else:\n",
        "    mask = np.ones(len(y_full), dtype=bool)\n",
        "\n",
        "# aplica a mesma máscara no alvo\n",
        "y = y_full[mask]\n",
        "\n",
        "if VERBOSE:\n",
        "    print(\"=\"*80)\n",
        "    if USE_ZSCORE:\n",
        "        print(f\"[INFO] Z-score |z|<={ZS_THRESH}: mantidas {mask.sum():,} / {len(mask):,} linhas\")\n",
        "    else:\n",
        "        print(f\"[INFO] Z-score DESATIVADO: usando {len(y):,} / {len(y_full):,} linhas\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "def RMSE(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def _fmt(x):  # formato curto para métrica\n",
        "    return f\"{x:.4f}\"\n",
        "\n",
        "def roda_um_feature_set(tag, cols, n_runs=N_RUNS, seed=SEED_BASE) -> pd.DataFrame:\n",
        "    X_all = df.loc[:, cols].copy()\n",
        "    X_all = X_all[mask]  # aplica máscara do alvo\n",
        "    n_rows, n_cols = X_all.shape\n",
        "\n",
        "    if VERBOSE:\n",
        "        print(f\"\\n--- [{tag}] Iniciando ({n_cols} variáveis, {n_rows} linhas após Z-score) ---\")\n",
        "        preview = \", \".join(cols[:5]) + (\"...\" if len(cols) > 5 else \"\")\n",
        "        print(f\"[{tag}] primeiras variáveis: {preview}\")\n",
        "\n",
        "    # RNG determinístico a partir do seed base, mas gera uma semente nova a cada run\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    rows = []\n",
        "    t0_tag = time()\n",
        "    for i in range(n_runs):\n",
        "        t0 = time()\n",
        "\n",
        "        run_seed = int(rng.integers(1_000_000))\n",
        "\n",
        "        # split varia a cada run\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_all, y, test_size=0.20, random_state=run_seed\n",
        "        )\n",
        "        if VERBOSE and ((i % PRINT_EVERY) == 0):\n",
        "            print(f\"[{tag}][run {i+1:02d}/{n_runs}] split: \"\n",
        "                  f\"train={len(X_train):,} | test={len(X_test):,} | seed={run_seed}\")\n",
        "\n",
        "        modelos = {\n",
        "            \"RF\":  RandomForestRegressor(\n",
        "                        n_estimators=200, min_samples_split=2, min_samples_leaf=2,\n",
        "                        max_features=\"sqrt\", max_depth=None, bootstrap=True,\n",
        "                        random_state=run_seed, n_jobs=-1\n",
        "                  ),\n",
        "            \"DT\": DecisionTreeRegressor(\n",
        "    max_depth=12,            # controla overfitting (ajuste 8–16 conforme o caso)\n",
        "    min_samples_split=20,\n",
        "    min_samples_leaf=5,\n",
        "    max_features=\"sqrt\",     # usa fração de features por split\n",
        "    random_state=run_seed\n",
        "),\n",
        "\n",
        "\"ADA\": AdaBoostRegressor(\n",
        "    estimator=DecisionTreeRegressor(  # base learner raso funciona bem\n",
        "        max_depth=3,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=run_seed\n",
        "    ),\n",
        "    n_estimators=400,         # mais árvores + learning_rate menor = estável\n",
        "    learning_rate=0.05,\n",
        "    loss=\"linear\",            # (linear | square | exponential) — deixe linear como padrão\n",
        "    random_state=run_seed\n",
        "),\n",
        "\n",
        "            \"XGB\": XGBRegressor(\n",
        "                        subsample=0.8, reg_lambda=10.0, reg_alpha=1.0,\n",
        "                        n_estimators=400, min_child_weight=5, max_depth=5,\n",
        "                        learning_rate=0.05, gamma=0.1, colsample_bytree=0.6,\n",
        "                        random_state=run_seed, n_jobs=-1, tree_method=\"hist\"\n",
        "                  ),\n",
        "            \"LGBM\": LGBMRegressor(\n",
        "                        num_leaves=2**12, max_depth=12, min_data_in_leaf=20,\n",
        "                        subsample=0.8, colsample_bytree=0.8,\n",
        "                        random_state=run_seed, verbose=-1\n",
        "                  ),\n",
        "            \"MLP\": Pipeline([\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('model', MLPRegressor(\n",
        "                    hidden_layer_sizes=(128, 64),\n",
        "                    activation='tanh', solver='adam',\n",
        "                    learning_rate='adaptive', learning_rate_init=1e-3,\n",
        "                    alpha=1e-4, max_iter=1000, early_stopping=True,\n",
        "                    validation_fraction=0.15, n_iter_no_change=20,\n",
        "                    shuffle=True, random_state=run_seed\n",
        "                ))\n",
        "            ]),\n",
        "            \"NAIVE\": DummyRegressor(strategy=\"mean\"),\n",
        "        }\n",
        "\n",
        "        # === aplica hiperparâmetros do CSV/JSON correspondente a este feature set ===\n",
        "        aplicar_hiperparams(tag, modelos)\n",
        "\n",
        "        metrics_row = {\"run\": i,\n",
        "                       f\"{tag}_N_features\": n_cols,\n",
        "                       f\"{tag}_rows_after_zscore\": n_rows}\n",
        "\n",
        "        # treina e mede\n",
        "        line_parts = []\n",
        "        for suf, model in modelos.items():\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            rmse = RMSE(y_test, y_pred)\n",
        "            mae  = mean_absolute_error(y_test, y_pred)\n",
        "            r2   = r2_score(y_test, y_pred)\n",
        "\n",
        "            metrics_row[f\"{tag}_RMSE_{suf}\"] = rmse\n",
        "            metrics_row[f\"{tag}_MAE_{suf}\"]  = mae\n",
        "            metrics_row[f\"{tag}_R2_{suf}\"]   = r2\n",
        "\n",
        "            line_parts.append(f\"{suf}: RMSE={_fmt(rmse)} R2={_fmt(r2)} MAE={_fmt(mae)}\")\n",
        "\n",
        "        rows.append(metrics_row)\n",
        "\n",
        "        if VERBOSE and ((i % PRINT_EVERY) == 0):\n",
        "            dt = time() - t0\n",
        "            print(f\"[{tag}][run {i+1:02d}] \" + \" | \".join(line_parts) + f\"   ({dt:.2f}s)\")\n",
        "\n",
        "    df_runs = pd.DataFrame(rows).sort_values(\"run\").reset_index(drop=True)\n",
        "\n",
        "    # resumo por modelo (média±desvio)\n",
        "    if VERBOSE:\n",
        "        import re\n",
        "        print(f\"[{tag}] Resumo (média ± desvio) nas {n_runs} runs:\")\n",
        "\n",
        "        # descobre os sufixos disponíveis a partir das colunas presentes\n",
        "        suf_set = set()\n",
        "        for c in df_runs.columns:\n",
        "            m = re.match(fr\"{tag}_RMSE_(.+)\", c)\n",
        "            if m:\n",
        "                suf_set.add(m.group(1))\n",
        "\n",
        "        # ordem de preferência + acrescenta qualquer sufixo extra ao final\n",
        "        prefer = [\"NAIVE\",\"DT\",\"RF\",\"GB\",\"ADA\",\"XGB\",\"LGBM\",\"MLP\"]\n",
        "        modelos_ordem = [s for s in prefer if s in suf_set] + [s for s in sorted(suf_set) if s not in prefer]\n",
        "\n",
        "        for suf in modelos_ordem:\n",
        "            rmse_vals = df_runs[f\"{tag}_RMSE_{suf}\"].values\n",
        "            r2_vals   = df_runs[f\"{tag}_R2_{suf}\"].values\n",
        "            mae_vals  = df_runs[f\"{tag}_MAE_{suf}\"].values\n",
        "            print(f\"  {suf:5s} | RMSE={_fmt(np.nanmean(rmse_vals))}±{_fmt(np.nanstd(rmse_vals))} \"\n",
        "                  f\"| R2={_fmt(np.nanmean(r2_vals))}±{_fmt(np.nanstd(r2_vals))} \"\n",
        "                  f\"| MAE={_fmt(np.nanmean(mae_vals))}±{_fmt(np.nanstd(mae_vals))}\")\n",
        "    print(f\"[{tag}] Tempo total: {time()-t0_tag:.2f}s\\n\")\n",
        "\n",
        "    return df_runs\n",
        "\n",
        "# ====== Rodar todos os conjuntos ======\n",
        "all_tags = list(FEATURE_SETS.keys())\n",
        "if VERBOSE:\n",
        "    print(\"Rodando feature sets:\", \", \".join(all_tags))\n",
        "\n",
        "dfs = [roda_um_feature_set(tag, cols, n_runs=N_RUNS, seed=SEED_BASE)\n",
        "       for tag, cols in FEATURE_SETS.items()]\n",
        "\n",
        "# ====== Merge por 'run' ======\n",
        "from functools import reduce\n",
        "out_df = reduce(lambda a, b: a.merge(b, on=\"run\", how=\"outer\"), dfs)\n",
        "\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "out_path = \"outputs/Model_Results_B_20_features.xlsx\"\n",
        "out_df.to_excel(out_path, index=False)\n",
        "print(\"=\"*80)\n",
        "print(\"Arquivo salvo:\", out_path)\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "JxOkcbE_JaJg",
        "outputId": "6798aca6-36b3-488d-c718-9359fdcdca96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4207565552.py:191: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = ax.boxplot(data, labels=[tag_map.get(t,t) for t in tag_list], showfliers=False, patch_artist=True)\n",
            "/tmp/ipython-input-4207565552.py:191: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = ax.boxplot(data, labels=[tag_map.get(t,t) for t in tag_list], showfliers=False, patch_artist=True)\n",
            "/tmp/ipython-input-4207565552.py:191: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = ax.boxplot(data, labels=[tag_map.get(t,t) for t in tag_list], showfliers=False, patch_artist=True)\n",
            "/tmp/ipython-input-4207565552.py:191: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = ax.boxplot(data, labels=[tag_map.get(t,t) for t in tag_list], showfliers=False, patch_artist=True)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1680x400 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: ./facet_boxplot_1row_RMSE.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4207565552.py:191: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = ax.boxplot(data, labels=[tag_map.get(t,t) for t in tag_list], showfliers=False, patch_artist=True)\n",
            "/tmp/ipython-input-4207565552.py:191: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = ax.boxplot(data, labels=[tag_map.get(t,t) for t in tag_list], showfliers=False, patch_artist=True)\n",
            "/tmp/ipython-input-4207565552.py:191: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = ax.boxplot(data, labels=[tag_map.get(t,t) for t in tag_list], showfliers=False, patch_artist=True)\n",
            "/tmp/ipython-input-4207565552.py:191: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = ax.boxplot(data, labels=[tag_map.get(t,t) for t in tag_list], showfliers=False, patch_artist=True)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1680x400 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: ./facet_boxplot_1row_MAE.pdf\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# ==================== Config ====================\n",
        "INPUT_PATH   = \"Model_Results_BB_20_features.xlsx\"\n",
        "SAVE_DIR     = \".\"\n",
        "BASE_HEIGHT  = 5.0\n",
        "\n",
        "# >>> Filtros por MODELO (use os pretty names abaixo exatamente)\n",
        "EXCLUDE_SUFFIXES  = {\"ADA\",\"Gradient Boosting\"}   # aceita curto (RF, XGB...) ou nome completo\n",
        "EXCLUDE_MODELS_EN = set()\n",
        "INCLUDE_MODELS_EN = {\"Random Forest\", \"XGBoost\", \"LightGBM\", \"MLP\"}\n",
        "\n",
        "# >>> Filtros por TAG de features (F1, F2, ...)\n",
        "EXCLUDE_FEATURE_TAGS = {\"F5\", \"F6\", \"F7\", \"F8\"}  #\n",
        "INCLUDE_FEATURE_TAGS = None\n",
        "\n",
        "\n",
        "MODEL_ORDER   = [\"Random Forest\", \"XGBoost\", \"LightGBM\", \"MLP\"]\n",
        "FEATURE_ORDER = [\"F1\", \"F2\", \"F3\", \"F4\"]\n",
        "\n",
        "# ==================== Imports ====================\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# ==================== Estilo ====================\n",
        "plt.rcParams['pdf.fonttype'] = 42\n",
        "plt.rcParams['ps.fonttype']  = 42\n",
        "plt.rcParams.update({\n",
        "    \"font.family\": \"serif\",\n",
        "    \"axes.edgecolor\": \"black\",\n",
        "    \"axes.linewidth\": 1.2,\n",
        "    \"axes.grid\": True,\n",
        "    \"grid.color\": \"gray\",\n",
        "    \"grid.alpha\": 0.5,\n",
        "    \"grid.linestyle\": \"--\",\n",
        "    \"grid.linewidth\": 0.5,\n",
        "    \"font.size\": 12,\n",
        "    \"text.usetex\": False\n",
        "})\n",
        "\n",
        "# ==================== Helpers ====================\n",
        "def normalize_colname(s: str) -> str:\n",
        "    s = str(s).strip()\n",
        "    s = s.replace(\"R²\", \"R2\").replace(\"R^2\", \"R2\").replace(\"R_2\", \"R2\")\n",
        "    s = s.replace(\"-\", \"_\").replace(\" \", \"_\").replace(\".\", \"_\").replace(\"/\", \"_\")\n",
        "    s = re.sub(r\"[()\\[\\]\\{\\}]\", \"\", s)\n",
        "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
        "    return s\n",
        "\n",
        "def _as_feat_tag_from_prefix(prefix: str) -> str | None:\n",
        "    m = re.match(r'(?i)^(features?|feat)(\\d+)$', prefix)\n",
        "    if m:\n",
        "        return f\"F{m.group(2)}\"\n",
        "    return None\n",
        "\n",
        "MODEL_NAME_MAP = {\n",
        "    \"RF\": \"Random Forest\",\n",
        "    \"DT\": \"Decision Tree\",\n",
        "    \"ADA\": \"AdaBoost\",\n",
        "    \"GB\": \"Gradient Boosting\",\n",
        "    \"XGB\": \"XGBoost\",\n",
        "    \"LGBM\": \"LightGBM\",\n",
        "    \"NAIVE\": \"Naive\",\n",
        "    \"MLP\": \"MLP\",\n",
        "}\n",
        "MODEL_NAME_MAP.update({v.upper(): v for v in MODEL_NAME_MAP.values()})\n",
        "YLABEL_BY_METRIC = {\"RMSE\": \"RMSE (%)\", \"MAE\": \"MAE (%)\", \"R2\": \"R-squared\"}\n",
        "EXCLUDE_SUFFIXES_UP = {s.upper() for s in EXCLUDE_SUFFIXES}\n",
        "col_pat_cache = {}\n",
        "\n",
        "def parse_col(metric: str, col: str):\n",
        "    key = (metric, col)\n",
        "    if key in col_pat_cache:\n",
        "        return col_pat_cache[key]\n",
        "    s = str(col)\n",
        "    # Formato A: METRIC_MODEL[_F#]\n",
        "    if re.match(fr'(?i)^{metric}_', s):\n",
        "        rest = re.sub(fr'(?i)^{metric}_', '', s)\n",
        "        parts = rest.split('_')\n",
        "        if len(parts) == 1:\n",
        "            model_suffix = parts[0]\n",
        "            feat_tag = None\n",
        "        else:\n",
        "            model_suffix = '_'.join(parts[:-1])\n",
        "            last = parts[-1]\n",
        "            feat_tag = last if re.match(r'(?i)^F\\d+$', last) else None\n",
        "            if feat_tag is None:\n",
        "                model_suffix = rest\n",
        "        col_pat_cache[key] = (model_suffix, feat_tag)\n",
        "        return col_pat_cache[key]\n",
        "    # Formato B: featureN_METRIC_MODEL\n",
        "    m = re.match(fr'(?i)^(features?\\d+)_({metric})_(.+)$', s)\n",
        "    if m:\n",
        "        feat_prefix = m.group(1)\n",
        "        model_suffix = m.group(3)\n",
        "        feat_tag = _as_feat_tag_from_prefix(feat_prefix)\n",
        "        col_pat_cache[key] = (model_suffix, feat_tag)\n",
        "        return col_pat_cache[key]\n",
        "    col_pat_cache[key] = None\n",
        "    return None\n",
        "\n",
        "def pretty_model_name(model_suffix: str) -> str:\n",
        "    return MODEL_NAME_MAP.get(model_suffix.upper(), model_suffix)\n",
        "\n",
        "def label_with_tag(pretty_model: str, feat_tag: str | None) -> str:\n",
        "    return f\"{pretty_model}_{feat_tag}\" if feat_tag else pretty_model\n",
        "\n",
        "def split_label(label: str):\n",
        "    m = re.match(r'^(.*?)(?:_(F\\d+))?$', label)\n",
        "    if m: return m.group(1), m.group(2)\n",
        "    return label, None\n",
        "\n",
        "def wide_for_metric(df_in: pd.DataFrame, metric: str) -> pd.DataFrame:\n",
        "    cols_meta = []\n",
        "    for c in df_in.columns:\n",
        "        parsed = parse_col(metric, c)\n",
        "        if parsed is None: continue\n",
        "        model_suffix, feat_tag = parsed\n",
        "        if model_suffix.upper() in EXCLUDE_SUFFIXES_UP: continue\n",
        "        pretty = pretty_model_name(model_suffix)\n",
        "        if EXCLUDE_MODELS_EN and pretty in EXCLUDE_MODELS_EN: continue\n",
        "        if INCLUDE_MODELS_EN and pretty not in INCLUDE_MODELS_EN: continue\n",
        "        if feat_tag and feat_tag in EXCLUDE_FEATURE_TAGS: continue\n",
        "        cols_meta.append((c, model_suffix, feat_tag))\n",
        "    if not cols_meta: return pd.DataFrame()\n",
        "    sub = df_in[[c for (c, _, _) in cols_meta]].apply(pd.to_numeric, errors=\"coerce\").copy()\n",
        "    if metric.upper() == \"R2\": sub = sub.where(sub >= 0, np.nan)\n",
        "    new_cols = [label_with_tag(pretty_model_name(m), t) for _, m, t in cols_meta]\n",
        "    sub.columns = new_cols\n",
        "    return sub.loc[:, sub.notna().any(axis=0)]\n",
        "\n",
        "def order_with_reference(items, ref):\n",
        "    out = [x for x in ref if x in items]\n",
        "    out += [x for x in items if x not in out]\n",
        "    return out\n",
        "\n",
        "# ==================== Ler & preparar dados ====================\n",
        "df = pd.read_excel(INPUT_PATH)\n",
        "df = df.rename(columns={c: normalize_colname(c) for c in df.columns})\n",
        "\n",
        "ALL_METRICS = [\"RMSE\", \"MAE\"]\n",
        "metrics = [m for m in ALL_METRICS if any(df.columns.str.contains(fr'(?i)_{m}_'))]\n",
        "\n",
        "# ==================== Plot ====================\n",
        "for metric in metrics:\n",
        "    sub = wide_for_metric(df, metric)\n",
        "    if sub.empty:\n",
        "        print(f\"[WARN] Sem dados válidos para {metric}.\")\n",
        "        continue\n",
        "\n",
        "    by_model = {}\n",
        "    all_tags = set()\n",
        "    for col in sub.columns:\n",
        "        mdl, tag = split_label(col)\n",
        "        tag = tag or \"Only\"\n",
        "        vals = pd.to_numeric(sub[col], errors=\"coerce\").dropna().values\n",
        "        if vals.size == 0: continue\n",
        "        by_model.setdefault(mdl, {})[tag] = vals\n",
        "        all_tags.add(tag)\n",
        "\n",
        "    if not by_model: continue\n",
        "\n",
        "    models = order_with_reference(by_model.keys(), MODEL_ORDER)\n",
        "    tags = order_with_reference(all_tags, FEATURE_ORDER)\n",
        "\n",
        "    # Map F1-F4 -> m1-m4\n",
        "    tag_map = {f\"F{i}\": f\"m{i}\" for i in range(1, 5)}\n",
        "    tags_mapped = [tag_map.get(t, t) for t in tags]\n",
        "\n",
        "    palette = sns.color_palette(\"pastel\", len(tags_mapped))\n",
        "    TAG_COLOR = {tags_mapped[i]: palette[i] for i in range(len(tags_mapped))}\n",
        "\n",
        "    n_models = len(models)\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=n_models, figsize=(4.2*n_models, 4))\n",
        "    if n_models == 1: axes = [axes]\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    global_vals = np.concatenate([v for d in by_model.values() for v in d.values()])\n",
        "    y_min, y_max = np.nanmin(global_vals), np.nanmax(global_vals)\n",
        "    pad = 0.02 * (y_max - y_min)\n",
        "    y_lim = (y_min - pad, y_max + pad)\n",
        "\n",
        "    for ax, mdl in zip(axes, models):\n",
        "        per_tag = by_model.get(mdl, {})\n",
        "        tag_list = [t for t in tags if t in per_tag]\n",
        "        if not tag_list: ax.axis(\"off\"); continue\n",
        "        data = [per_tag[t] for t in tag_list]\n",
        "        bp = ax.boxplot(data, labels=[tag_map.get(t,t) for t in tag_list], showfliers=False, patch_artist=True)\n",
        "        for patch, t in zip(bp['boxes'], [tag_map.get(t,t) for t in tag_list]):\n",
        "            patch.set_facecolor(TAG_COLOR[t])\n",
        "            patch.set_edgecolor(\"black\")\n",
        "            patch.set_linewidth(1.2)\n",
        "        for whisker in bp['whiskers']: whisker.set(color=\"black\", linewidth=1.2)\n",
        "        for cap in bp['caps']: cap.set(color=\"black\", linewidth=1.2)\n",
        "        for median in bp['medians']: median.set(color=\"orange\", linewidth=1.5)\n",
        "        ax.set_title(mdl, fontsize=16)\n",
        "        ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "        ax.set_ylim(*y_lim)\n",
        "        plt.setp(ax.get_xticklabels(), rotation=0, ha='center', fontsize=14)\n",
        "\n",
        "    axes[0].set_ylabel(YLABEL_BY_METRIC.get(metric, metric), fontsize=16, labelpad=15)\n",
        "    for ax in axes[1:]: ax.set_ylabel(\"\")\n",
        "\n",
        "    if metric.upper() == \"R2\":\n",
        "        for ax in axes: ax.set_ylim(0, max(1.05, y_lim[1]))\n",
        "\n",
        "    # handles = [Patch(facecolor=TAG_COLOR[t], edgecolor=\"black\", label=t) for t in tags_mapped]\n",
        "    # fig.legend(handles=handles, title=\"Feature set\", loc=\"lower center\",\n",
        "    #            bbox_to_anchor=(0.5, -0.02), ncol=len(tags_mapped), frameon=True)\n",
        "\n",
        "    plt.tight_layout(rect=[0.06, 0.18, 0.98, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "    out_pdf = os.path.join(SAVE_DIR, f\"facet_boxplot_1row_{metric}.pdf\")\n",
        "    fig.savefig(out_pdf, format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    print(f\"Saved: {out_pdf}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
